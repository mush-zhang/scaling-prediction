{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b040608c-b6b2-484a-97ec-0d2c3ae19811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "from helpers.expr_data import ExprData\n",
    "from helpers.scale_data import ScaleData\n",
    "from helpers.similarity import Similarity\n",
    "from helpers.feature_selection import FeatureSelection\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import root_mean_squared_error as rmse_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19d30e8-774c-4feb-b1d8-e7e260fc16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "SMALL_SMALL_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "plt.rc('legend', fontsize=SMALL_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29ae11c-eee0-4d6a-b83e-c6c0a2835925",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2ffc80-d57c-4347-9191-6897c280625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label = 'SKU'\n",
    "expr_label = 'EXPR'\n",
    "y_true_label = 'Y_TRUE'\n",
    "y_pred_label = 'Y_PRED'\n",
    "suffix_labels = ['_small', '_large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfa50a2-27bc-4d9e-bac2-fd57b5e49124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(47907)\n",
    "random.seed(47907)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8849241e-37b3-4345-b1da-d6572aa243a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse_score(y_true, y_pred):\n",
    "    # return np.sqrt((((y_true-y_pred)/y_pred)**2).mean())\n",
    "    # return (abs(y_true-y_pred)/y_pred).mean()\n",
    "    # return rmse_score(y_true, y_pred)/(np.mean(y_true))\n",
    "    return rmse_score(y_true, y_pred)/(np.max(y_true)-np.min(y_true))\n",
    "score_func = make_scorer(nrmse_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b597f4-f58e-480c-9856-b48fa0de744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the performance metrics for each experiment\n",
    "data_all = ExprData()\n",
    "data_all.load_pickle()\n",
    "data = data_all.remove_by_wlname(['xml', 'ycsb'])\n",
    "ycsb_data = data_all.remove_by_wlname(['xml', 'tpcc', 'tpch', 'twitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ade028-0568-4894-a9f1-b3e844c0c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fix_tpch()\n",
    "data = data.merge_tpch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74f5e95-30ac-42ce-b1d8-6310c9b7a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity for all\n",
    "new_data = data.keep_complete_exprs()\n",
    "\n",
    "scaler = ScaleData()\n",
    "plan_mtxs, plan_col_ranges = scaler.scale(new_data.plan_mtxs)\n",
    "perf_mtxs, perf_col_ranges = scaler.scale(new_data.perf_mtxs)\n",
    "\n",
    "simi_calc_all = Similarity(new_data, plan_mtxs, plan_col_ranges, perf_mtxs, perf_col_ranges)\n",
    "simi_calc_all.calc_bined_mtx() # all plan features\n",
    "\n",
    "simi_calc = simi_calc_all\n",
    "fs = FeatureSelection(simi_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df02f90-bcd6-4342-9a00-cfce693deb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = new_data.sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e5e309-a1d7-4819-897b-4ce9d1c27e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_type = sampled_data.split_by_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ec1e18-1336-4752-9197-e588b9cc17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_by_type = sampled_data.split_by_type()\n",
    "for ty, expr_set in sampled_by_type.items():\n",
    "    sub_by_term = expr_set.split_by_term()\n",
    "    sampled_by_type[ty] = sub_by_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f50be2-f21d-46ce-b20b-65eed7e96283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_nums_as_X(l):\n",
    "    return np.array([int(e[3:]) for e in l]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef55cdf6-8994-4a3f-b4b8-c047f866c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "all_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4fb0f65-42ff-4b7b-91eb-3379ad6aa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label = 'cpu_num'\n",
    "y_label = 'latency'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f301f1b1-1168-4faa-87b3-d4c4dd10671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_by_cpus(X, y, cpu_a, cpu_b):\n",
    "    bigger_mask = [x_lab == cpu_b for x_lab in X.flatten()]\n",
    "    smaller_mask = [x_lab == cpu_a for x_lab in X.flatten()]\n",
    "\n",
    "    curr_y_true = y[bigger_mask]\n",
    "    # curr_y_pred = y[smaller_mask]*(cpu_b/cpu_a)\n",
    "    curr_y_pred = y[smaller_mask]*(cpu_a/cpu_b)\n",
    "    n_rmse = nrmse_score(curr_y_true, curr_y_pred)\n",
    "    return n_rmse\n",
    "\n",
    "def get_baseline_scores(X, y, wl_name, grouping_type, groupping_id):  \n",
    "    train_rmses, test_rmses = [], []\n",
    "    k = 5\n",
    "    num_cpus = np.sort(np.unique(X))\n",
    "    train_time = 0\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X, X.flatten()):\n",
    "        start = time.time()\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        end = time.time()\n",
    "        train_time += end - start\n",
    "        for i in range(len(num_cpus)):\n",
    "            for j in range(i, len(num_cpus)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                cpu_a = num_cpus[i] # smaller\n",
    "                cpu_b = num_cpus[j] # larger\n",
    "\n",
    "                test_rmses.append(get_score_by_cpus(X_test, y_test, cpu_a, cpu_b))\n",
    "                train_rmses.append(get_score_by_cpus(X_train, y_train, cpu_a, cpu_b))\n",
    "\n",
    "    \n",
    "    train_time /= k\n",
    "    overall_test_rmse = np.mean(test_rmses)\n",
    "    overall_train_rmse = np.mean(train_rmses)\n",
    "    return overall_test_rmse, overall_train_rmse, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f11589-139d-4d11-a87d-c09e344d2775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Id: 1, wl name tpcc, terminal num 32\n",
      "Test rmse = 17.958665969123523, Train rmse = 11.687422938024717\n",
      "Group Id: 2, wl name tpch, terminal num 1\n",
      "Test rmse = 0.5515308448026249, Train rmse = 0.44111751462776394\n",
      "Group Id: 3, wl name twitter, terminal num 32\n",
      "Test rmse = 90.96997590140539, Train rmse = 63.784158884038305\n",
      "Group Id: 4, wl name twitter, terminal num 8\n",
      "Test rmse = 67.34117237789143, Train rmse = 43.33022795519159\n",
      "Group Id: 7, wl name tpcc, terminal num 8\n",
      "Test rmse = 12.503082486878801, Train rmse = 8.876188073772932\n",
      "Group Id: 8, wl name tpcc, terminal num 4\n",
      "Test rmse = 9.896702360513567, Train rmse = 8.202993399119906\n",
      "Group Id: 9, wl name twitter, terminal num 4\n",
      "Test rmse = 21.071702537854375, Train rmse = 16.40488132784905\n",
      "Overall test nrmse: 31.470404639781385, train 21.81814144180347\n"
     ]
    }
   ],
   "source": [
    "all_tests, all_trains = [], []\n",
    "all_results['Baseline'] = {}\n",
    "all_times['Baseline'] = {}\n",
    "\n",
    "for ty, curr_data in data_by_type.items():\n",
    "    name = curr_data.wl_names[0]\n",
    "    term = curr_data.terminal_num[0]\n",
    "    if name not in all_results['Baseline']:\n",
    "        all_results['Baseline'][name] = {}\n",
    "        all_times['Baseline'][name] = {}\n",
    "    print(f'Group Id: {ty}, wl name {name}, terminal num {term}')\n",
    "    \n",
    "    X = get_cpu_nums_as_X(curr_data.cpu_nums)\n",
    "    y = np.array(curr_data.wl_latency)\n",
    "    # y = np.array(curr_data.wl_throughput)\n",
    "    test_r2_mean, train_r2_mean, train_time = get_baseline_scores(X, y, curr_data.wl_names[0], 'group', \n",
    "                                                                     curr_data.wl_groups[0])\n",
    "    print('Test rmse = {}, Train rmse = {}'.format(test_r2_mean, train_r2_mean))\n",
    "    all_tests.append(test_r2_mean)\n",
    "    all_trains.append(train_r2_mean)\n",
    "    all_results['Baseline'][name][term] = test_r2_mean\n",
    "    all_times['Baseline'][name][term] = train_time\n",
    "print('Overall test nrmse: {}, train {}'.format(np.mean(all_tests), np.mean(all_trains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71ad0b07-363b-44cc-8c15-808b37817886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& Baseline &  0.0000 &  9.897 & 12.503 & 17.959 & 21.072 & 67.341 & 90.970 & 0.552 & 31.5 \\\\ \\cline{2-11}\n"
     ]
    }
   ],
   "source": [
    "terminals = [4, 8, 32]\n",
    "workloads = ['tpcc', 'twitter', 'tpch']\n",
    "methods = ['Baseline']\n",
    "for me in methods:\n",
    "    curr_line = ''\n",
    "    scs = []\n",
    "    times = []\n",
    "    for wl in workloads:\n",
    "        if wl == 'tpch':\n",
    "            sc = abs(all_results[me][wl][1])\n",
    "            curr_line += f' {sc:.3f} &'\n",
    "            scs.append(sc)\n",
    "            times.append(all_times[me][wl][1])\n",
    "        else:\n",
    "            for ter in terminals:\n",
    "                sc = abs(all_results[me][wl][ter])\n",
    "                curr_line += f' {sc:.3f} &'\n",
    "                scs.append(sc)\n",
    "                times.append(all_times[me][wl][ter])\n",
    "    curr_line += f' {np.mean(scs):.3}'\n",
    "    curr_line += \" \\\\\\\\ \\cline{2-11}\"\n",
    "    curr_line = f'& {me} & ' + f' {np.mean(times):.4f} & ' + curr_line\n",
    "    print(curr_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28051b02-f0a7-41bc-b3dc-40785c86ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\\hlrfive{Baseline} & \\hlrfive{0.0000} &  \\hlrfive{9.897} & \\hlrfive{12.503} & \\hlrfive{17.959} & \\hlrfive{21.072} & \\hlrfive{67.341} & \\hlrfive{90.970} & \\hlrfive{0.552} &\\hlrfive{31.470} \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "terminals = [4, 8, 32]\n",
    "workloads = ['tpcc', 'twitter', 'tpch']\n",
    "methods = ['Baseline']\n",
    "\n",
    "for me in methods:\n",
    "    curr_line = ''\n",
    "    scs = []\n",
    "    times = []\n",
    "    for wl in workloads:\n",
    "        if wl == 'tpch':\n",
    "            sc = abs(all_results[me][wl][1])\n",
    "            curr_line += ' \\hlrfive{'\n",
    "            curr_line += f'{sc:.3f}'\n",
    "            curr_line += '} &'\n",
    "            scs.append(sc)\n",
    "            times.append(all_times[me][wl][1])\n",
    "        else:\n",
    "            for ter in terminals:\n",
    "                sc = abs(all_results[me][wl][ter])\n",
    "                curr_line += ' \\hlrfive{'\n",
    "                curr_line += f'{sc:.3f}'\n",
    "                curr_line += '} &'\n",
    "                scs.append(sc)\n",
    "                times.append(all_times[me][wl][ter])\n",
    "    curr_line += '\\hlrfive{' + f'{np.mean(scs):.3f}'+'}'\n",
    "    # curr_line += \" \\\\\\\\ \\cline{2-11}\"\n",
    "    curr_line += \" \\\\\\\\ \\hline\"\n",
    "    curr_line = '&\\hlrfive{' + f'{me}' + '} & \\hlrfive{' + f'{np.mean(times):.4f}' + '} & ' + curr_line\n",
    "    print(curr_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1219c-ccec-4105-ae25-ddc7b94a94ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload_insights",
   "language": "python",
   "name": "workload_insights"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
