{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc07ed-a9e1-4257-83ef-5b758666bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Table 3, include all but Lasso and Elastic net\n",
    "# k = 1 cpu = 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import compress\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import lasso_path, enet_path, LogisticRegression, ElasticNet, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE, SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.feature_selection import f_classif, chi2, mutual_info_classif, r_regression\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from helpers import expr_data\n",
    "from helpers import scale_data\n",
    "from helpers import similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11b96fb-66df-492d-ab4b-08f7e96e94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37663de8-c366-46b6-95ad-e0c5cbc432bf",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d781e6-951b-4f76-ab71-2fb8d5963c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = expr_data.ExprData()\n",
    "data.load_pickle()\n",
    "data = data.fix_tpch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f438a-632d-4486-bd01-deea57cd02fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split by SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbdbae2-b3b0-4309-8945-330f41be72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_sku = data.split_by_sku()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cc264-c8ee-4a29-b419-d668be0bd37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2a954-220e-4a39-8b69-30afe288e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result sku_result is a dict with its key the SKU,\n",
    "# the value a list, the classification accuracy for each f_num\n",
    "data_dist = {}\n",
    "\n",
    "for sku in data_by_sku.keys():\n",
    "    curr_data = data_by_sku[sku]\n",
    "    if 'ter' in sku:\n",
    "        continue\n",
    "    scaler = scale_data.ScaleData()\n",
    "    plan_mtxs_splitted, plan_col_ranges = scaler.scale(curr_data.plan_mtxs)\n",
    "    perf_mtxs_splitted, perf_col_ranges = scaler.scale(curr_data.perf_mtxs)\n",
    "    simi_calc = similarity.Similarity(curr_data, plan_mtxs_splitted, plan_col_ranges, perf_mtxs_splitted, perf_col_ranges, num_bins=10)\n",
    "\n",
    "    simi_calc.calc_bined_mtx() # all features\n",
    "    simi_calc.calc_dist_simi_matrix(normalize=True)\n",
    "    print(simi_calc.simi_mtx.shape)\n",
    "    # feature wise distance\n",
    "    simi_calc.calc_featurewise_dist_by_col()\n",
    "    \n",
    "    data_dist[sku] = simi_calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82729bef-d6fe-4137-97db-ac81ced0bc11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select Top K Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "525bfc84-5958-495a-a2ff-2bde2ede6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return non-zero index in descending order\n",
    "def sparse_argsort(arr):\n",
    "    arr = np.where(np.isnan(arr), 0, arr)\n",
    "    arr = arr * -1\n",
    "    indices = np.nonzero(arr)[0]\n",
    "    result = indices[np.argsort(arr[indices])]\n",
    "    return result\n",
    "\n",
    "def all_argsort(arr):\n",
    "    arr = np.where(np.isnan(arr), 0, arr)\n",
    "    arr = arr * -1\n",
    "    result = np.argsort(arr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a46272-f1ec-4b10-857c-3550a72d29cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8819e-b7bb-4188-a4cb-fcc539bf9296",
   "metadata": {},
   "source": [
    "#### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003b606f-9b02-4594-852e-9ba6cbbc6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold(X, y):\n",
    "    selector = VarianceThreshold()\n",
    "    selector.fit(X)\n",
    "    scores = selector.variances_\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a01d8-ed86-408b-b6c1-1aa50f1b7215",
   "metadata": {},
   "source": [
    "#### fANOVA, Chi-Squared test, Mutual Information gain, Fisher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445c5fa9-527c-4470-ba14-45a3b85ddbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fANOVA, Chi-Squared test, Mutual Information gain, Fisher score\n",
    "def select_k_best(X, y, method):\n",
    "    if method == 'fANOVA':\n",
    "        selector = SelectKBest(f_classif, k='all')\n",
    "    elif method == 'Chi2':\n",
    "        selector = SelectKBest(chi2, k='all')\n",
    "    elif method == 'MutualInfoGain': # this uses knn=3 by default to do the feature selection \n",
    "        selector = SelectKBest(mutual_info_classif, k='all')  \n",
    "    elif method == 'Pearson': #https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.r_regression.htm\n",
    "        selector = SelectKBest(r_regression, k='all')  \n",
    "    selector.fit(X, y)\n",
    "    scores = np.absolute(selector.scores_)\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5c289-d4c4-4f00-a703-115dbe0fe124",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wrapper method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586c399-fcec-4073-8fcf-852ba206434c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RFE (Recursive feature elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710283bb-4b00-4ca8-a549-824995aec475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_est(est_name):\n",
    "    if est_name == 'DecisionTree':\n",
    "        estimator = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "    elif est_name == 'LogisticRegression':\n",
    "        estimator = LogisticRegression(n_jobs=4, C=0.01) # C, tol, \n",
    "    else: # est_name == 'Linear':\n",
    "        estimator = SVR(kernel=\"linear\", C=0.05, ) # kernel, degree, \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a156a2bb-3b98-47f3-84f0-1ca63132e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_orders(X, y, est_name):\n",
    "    estimator = get_est(est_name)\n",
    "    selector = RFE(estimator, n_features_to_select=1, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "    # ranks are: 1 for most important\n",
    "    scores = -1 * selector.ranking_\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c6ebc-84f0-45a2-b14f-06a1186d38d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SFS (Sequential Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1056f5-b5d4-4ded-8014-42da886ef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfs_orders(curr_data, direction, est_name, n):\n",
    "    num_features = len(curr_data.feature_cols)\n",
    "    feature_importance = np.array([0]*num_features)\n",
    "    expr_num = curr_data.get_num_exprs()\n",
    "\n",
    "    for i in range(expr_num):\n",
    "        # calculate label\n",
    "        curr_name = curr_data.wl_names[i]\n",
    "        y = [curr_name == name for name in curr_data.wl_names]\n",
    "        X = simi_calc.simi_col_mtx[i]\n",
    "        estimator = get_est(est_name)\n",
    "\n",
    "        selector = SequentialFeatureSelector(estimator, direction=direction.lower(), n_features_to_select=n, n_jobs=-1, cv=3)\n",
    "        selector = selector.fit(X, y)\n",
    "        mask = selector.get_support()\n",
    "        for idx in range(num_features):\n",
    "            feature_importance[idx] += mask[idx]\n",
    "    final_orders = sparse_argsort(feature_importance)[:n]\n",
    "    top_features = [curr_data.feature_cols[j] for j in final_orders]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7ab6a-adf6-40dc-8984-218d926ba27d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedded method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763fa0c-973a-41bf-83ea-8e24392222f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac35cd6-0b6b-4afa-b305-0e0db3f68149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used\n",
    "def lasso_weights_orders(X, y):\n",
    "    selector = SelectFromModel(estimator=LinearSVC(C=0.01, penalty=\"l1\", dual=False)).fit(X, y) # C \n",
    "    scores = np.abs(selector.estimator_.coef_[0])\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484f9bf-07ec-4106-aab3-401385aec920",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "098b0855-0048-4539-8e2a-bc15383f0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used\n",
    "def ridge_weights_orders(X, y):\n",
    "    selector = SelectFromModel(estimator=LinearSVC(C=0.01, penalty=\"l2\", dual=False)).fit(X, y)\n",
    "    scores = np.abs(selector.estimator_.coef_[0])\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce8a93-ffc5-4852-83e1-268ca1eb087a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature select main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5806b74d-8a98-4634-84fa-ad2a7bd6a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(curr_data, expr_num, simi_calc, method, note=None):\n",
    "\n",
    "    # create dict for all features\n",
    "    num_features = len(curr_data.feature_cols)\n",
    "    feature_importance = np.array([0]*num_features)\n",
    "    \n",
    "    for i in range(expr_num):\n",
    "        # calculate label\n",
    "        curr_name = curr_data.wl_names[i]\n",
    "        y = [curr_name == name for name in curr_data.wl_names]\n",
    "        # X = simi_calc.dist_by_col_cube[i]\n",
    "        X = simi_calc.simi_col_mtx[i]\n",
    "        \n",
    "        mask = np.ones(X.shape[0], dtype=bool)  \n",
    "        X = X[mask]#.reshape(-1, 1)\n",
    "                \n",
    "        if method == 'Lasso':\n",
    "            orders = lasso_weights_orders(X, y)\n",
    "        elif method == 'ENet':\n",
    "            orders = enet_weights_orders(X, y)\n",
    "        elif method == 'Variance':\n",
    "            orders = variance_threshold(X, y)\n",
    "        elif method == 'fANOVA':\n",
    "            orders = select_k_best(X, y, method='fANOVA')\n",
    "        elif method == 'Chi2':\n",
    "            orders = select_k_best(X, y, method='Chi2')\n",
    "        elif method == 'MutualInfoGain':\n",
    "            orders = select_k_best(X, y, method='MutualInfoGain')\n",
    "        elif method == 'Pearson':\n",
    "            orders = select_k_best(X, y, method='Pearson')\n",
    "        elif method == 'RFE':\n",
    "            orders = rfe_orders(X, y, note)\n",
    "\n",
    "        for idx in range(len(orders)):\n",
    "            # from 0 to last idx of orders\n",
    "            # the score = num_features - idx\n",
    "            #   for a entry with feature_idx important order idx idx\n",
    "            # the higher the order, the more the score\n",
    "            feature_importance[orders[idx]] += num_features-idx\n",
    "    final_orders = all_argsort(feature_importance)\n",
    "    top_features = [curr_data.feature_cols[j] for j in final_orders]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aaeaf3-3190-4a44-a65e-8fb0dbd067c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare Feature Selection with Similarity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa76e37-9eef-48a0-a450-eb9ba846edc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf2cedaf-4df1-4d1f-be62-aa5879ee0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = {}\n",
    "time_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f588563-bde0-4c63-825d-f799d0fbe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data_by_sku[list(data_by_sku.keys())[0]].feature_cols\n",
    "feature_num = len(all_features)\n",
    "\n",
    "knn_thresholds = [1, 2, 3]\n",
    "direct_methods = ['Variance', 'fANOVA', 'Chi2', 'MutualInfoGain', 'Pearson', 'Lasso', 'Ridge']\n",
    "wrapper_methods = ['RFE']\n",
    "estimator_names = ['Linear', 'DecisionTree', 'LogisticRegression']\n",
    "other_methods = ['SFS', ]\n",
    "simi_method = 'KNN'\n",
    "\n",
    "f_nums = [1, 3, 7, 15, feature_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44d0b4c-6956-40a8-ba82-585884704bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Variance\n",
      "0.019920861721038817\n",
      "fANOVA\n",
      "0.03983873128890991\n",
      "Chi2\n",
      "0.062112510204315186\n",
      "MutualInfoGain\n",
      "2.4026515007019045\n",
      "Pearson\n",
      "0.02980543375015259\n",
      "Lasso\n",
      "0.04856536388397217\n",
      "Ridge\n",
      "0.05086199045181274\n",
      "2\n",
      "Variance\n",
      "0.022982406616210937\n",
      "fANOVA\n",
      "0.04169530868530273\n",
      "Chi2\n",
      "0.06010161638259888\n",
      "MutualInfoGain\n",
      "2.2380417943000794\n",
      "Pearson\n",
      "0.028130996227264404\n",
      "Lasso\n",
      "0.048056495189666745\n",
      "Ridge\n",
      "0.04831134080886841\n",
      "3\n",
      "Variance\n",
      "0.02095578908920288\n",
      "fANOVA\n",
      "0.039502954483032225\n",
      "Chi2\n",
      "0.06157795190811157\n",
      "MutualInfoGain\n",
      "2.2175882339477537\n",
      "Pearson\n",
      "0.029135119915008546\n",
      "Lasso\n",
      "0.04887100458145142\n",
      "Ridge\n",
      "0.05004221200942993\n"
     ]
    }
   ],
   "source": [
    "for knn_threshold in knn_thresholds:\n",
    "    print(knn_threshold)\n",
    "    \n",
    "    if knn_threshold not in main_dict:\n",
    "        main_dict[knn_threshold] = {}\n",
    "        time_dict[knn_threshold] = {}\n",
    "    for fs_method in direct_methods:\n",
    "        print(fs_method)\n",
    "        curr_method = {}\n",
    "\n",
    "        for f_num in f_nums:\n",
    "            curr_method[f_num] = []\n",
    "        elapsed = []\n",
    "        for sku in data_by_sku.keys():    \n",
    "            if 'ter' in sku:\n",
    "                continue\n",
    "            curr_data = data_by_sku[sku]\n",
    "            curr_calc = data_dist[sku]\n",
    "            expr_num = curr_data.get_num_exprs()\n",
    "        \n",
    "            all_accs = []\n",
    "            # run 10 times to get the average\n",
    "            num_repeats = 5\n",
    "            for i in range(num_repeats):       \n",
    "                curr_accs = []\n",
    "                start_time = time.time()\n",
    "                top_features = get_top_features(curr_data, expr_num, curr_calc, fs_method, None)\n",
    "                f_features = [top_features[:n] for n in f_nums]\n",
    "                elapsed.append(time.time() - start_time)\n",
    "\n",
    "                for f_num, curr_f in zip(f_nums, f_features):\n",
    "                    curr_calc.calc_dist_simi_matrix(feature_names=curr_f)\n",
    "                    pen, pens = curr_calc.simi_penalty(n=knn_threshold, dependent=True)\n",
    "\n",
    "                    acc = 1 - (np.sum(pens)/(len(pens)*10))\n",
    "                    curr_accs.append(acc)\n",
    "                all_accs.append(curr_accs)\n",
    "            all_accs = np.average(np.array(all_accs), axis=0)\n",
    "            for f_num, acc in zip(f_nums, all_accs):\n",
    "                curr_method[f_num].append(acc)\n",
    "        main_dict[knn_threshold][fs_method] = curr_method\n",
    "        time_dict[knn_threshold][fs_method] = np.mean(elapsed)\n",
    "        print(np.mean(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4f83037-e206-41e7-af39-1ba7f494f9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "RFE Linear\n",
      "1.1427931785583496\n",
      "1.2453176975250244\n",
      "1.1666507720947266\n",
      "1.1654529571533203\n",
      "1.1564786434173584\n",
      "1.0471961498260498\n",
      "0.9480254650115967\n",
      "0.8866641521453857\n",
      "0.9317972660064697\n",
      "0.99111008644104\n",
      "1.1839320659637451\n",
      "1.1457054615020752\n",
      "1.1397418975830078\n",
      "1.1389868259429932\n",
      "1.2153856754302979\n",
      "1.2917003631591797\n",
      "1.1391184329986572\n",
      "1.2313146591186523\n",
      "1.2053768634796143\n",
      "1.1971681118011475\n",
      "RFE DecisionTree\n",
      "1.2365655899047852\n",
      "1.2155547142028809\n",
      "1.167820692062378\n",
      "1.2284789085388184\n",
      "1.2097644805908203\n",
      "1.1370701789855957\n",
      "1.1596333980560303\n",
      "1.1356406211853027\n",
      "1.2304506301879883\n",
      "1.2583816051483154\n",
      "1.2438724040985107\n",
      "1.2047629356384277\n",
      "1.2223808765411377\n",
      "1.2022883892059326\n",
      "1.2112970352172852\n",
      "1.1805405616760254\n",
      "1.2138521671295166\n",
      "1.262557029724121\n",
      "1.230731725692749\n",
      "1.0961802005767822\n",
      "RFE LogisticRegression\n",
      "34.02939224243164\n",
      "17.643675804138184\n",
      "17.653817653656006\n",
      "17.38099479675293\n",
      "17.844050407409668\n",
      "17.882221698760986\n",
      "17.878328323364258\n",
      "18.089991092681885\n",
      "18.076930284500122\n",
      "17.687262535095215\n",
      "18.319873094558716\n",
      "18.64102077484131\n",
      "18.6246497631073\n",
      "18.39153814315796\n",
      "18.38063144683838\n",
      "18.354729652404785\n",
      "18.229952335357666\n",
      "18.454352855682373\n",
      "18.474219799041748\n",
      "18.677017211914062\n",
      "2\n",
      "RFE Linear\n",
      "1.1387670040130615\n",
      "1.0489587783813477\n",
      "1.1385867595672607\n",
      "1.1600065231323242\n",
      "1.1398019790649414\n",
      "0.9725658893585205\n",
      "1.1276123523712158\n",
      "1.1363167762756348\n",
      "1.129575490951538\n",
      "1.0338051319122314\n",
      "1.2229106426239014\n",
      "1.149181842803955\n",
      "1.1743931770324707\n",
      "1.1802940368652344\n",
      "1.1962330341339111\n",
      "1.114518642425537\n",
      "1.194368839263916\n",
      "1.0931637287139893\n",
      "1.1858799457550049\n",
      "1.1715383529663086\n",
      "RFE DecisionTree\n",
      "1.1092958450317383\n",
      "1.1698157787322998\n",
      "1.2691400051116943\n",
      "1.2119381427764893\n",
      "1.1984543800354004\n",
      "1.1727230548858643\n",
      "1.0941588878631592\n",
      "1.2240066528320312\n",
      "1.1411218643188477\n",
      "1.1856694221496582\n",
      "1.1887469291687012\n",
      "1.230823040008545\n",
      "1.2103197574615479\n",
      "1.177375078201294\n",
      "1.2468605041503906\n",
      "1.2419788837432861\n",
      "1.2422475814819336\n",
      "1.1964128017425537\n",
      "1.2859084606170654\n",
      "1.422675371170044\n",
      "RFE LogisticRegression\n",
      "18.743245840072632\n",
      "18.698957920074463\n",
      "18.760424613952637\n",
      "18.848265647888184\n",
      "18.99088978767395\n",
      "19.117594242095947\n",
      "19.496581554412842\n",
      "19.519994020462036\n",
      "19.677918672561646\n",
      "20.13521099090576\n",
      "19.944156646728516\n",
      "19.70161724090576\n",
      "19.249489784240723\n",
      "19.8849356174469\n",
      "19.928008794784546\n",
      "20.162031412124634\n",
      "20.296643018722534\n",
      "20.286797761917114\n",
      "19.700366020202637\n",
      "20.616612672805786\n",
      "3\n",
      "RFE Linear\n",
      "1.2321422100067139\n",
      "1.091604471206665\n",
      "1.1748881340026855\n",
      "1.163313865661621\n",
      "1.1850881576538086\n",
      "1.107302188873291\n",
      "1.1995818614959717\n",
      "1.2043757438659668\n",
      "1.1601238250732422\n",
      "1.1973464488983154\n",
      "1.2094111442565918\n",
      "1.1678814888000488\n",
      "1.2189302444458008\n",
      "1.14400053024292\n",
      "1.203303575515747\n",
      "1.1733558177947998\n",
      "1.237741470336914\n",
      "1.2700469493865967\n",
      "1.1699891090393066\n",
      "1.1878793239593506\n",
      "RFE DecisionTree\n",
      "1.1523323059082031\n",
      "1.183065414428711\n",
      "1.1551802158355713\n",
      "1.2298393249511719\n",
      "1.1462035179138184\n",
      "1.1030492782592773\n",
      "1.2573018074035645\n",
      "1.2497448921203613\n",
      "1.0308871269226074\n",
      "1.1547958850860596\n",
      "1.2498245239257812\n",
      "1.2438428401947021\n",
      "1.1716947555541992\n",
      "1.2896158695220947\n",
      "1.1075589656829834\n",
      "1.1705653667449951\n",
      "1.1649096012115479\n",
      "1.1027066707611084\n",
      "1.2714648246765137\n",
      "1.1805312633514404\n",
      "RFE LogisticRegression\n",
      "20.523274421691895\n",
      "20.047726154327393\n",
      "20.73513150215149\n",
      "20.8115451335907\n",
      "20.906545877456665\n",
      "20.99957585334778\n",
      "21.040568113327026\n",
      "20.51812767982483\n",
      "21.26471519470215\n",
      "21.32832169532776\n",
      "21.300328016281128\n",
      "21.507895946502686\n",
      "21.282458543777466\n",
      "21.162959098815918\n",
      "21.61641550064087\n",
      "21.83526921272278\n",
      "21.780027151107788\n",
      "21.823334455490112\n",
      "24.20396375656128\n",
      "24.59309673309326\n"
     ]
    }
   ],
   "source": [
    "for knn_threshold in knn_thresholds:\n",
    "    print(knn_threshold)\n",
    "    \n",
    "    if knn_threshold not in main_dict:\n",
    "        main_dict[knn_threshold] = {}\n",
    "        time_dict[knn_threshold] = {}\n",
    "\n",
    "    for fs_method in wrapper_methods:\n",
    "        for est_name in estimator_names:\n",
    "            print(fs_method, est_name)\n",
    "            curr_method = {}\n",
    "\n",
    "            for f_num in f_nums:\n",
    "                curr_method[f_num] = []\n",
    "            elapsed = []\n",
    "            for sku in data_by_sku.keys():    \n",
    "                if 'ter' in sku:\n",
    "                    continue\n",
    "                curr_data = data_by_sku[sku]\n",
    "                curr_calc = data_dist[sku]\n",
    "                expr_num = curr_data.get_num_exprs()\n",
    "\n",
    "                all_accs = []\n",
    "                # run 10 times to get the average\n",
    "                num_repeats = 5\n",
    "                for i in range(num_repeats):       \n",
    "                    curr_accs = []\n",
    "                    start_time = time.time()\n",
    "                    top_features = get_top_features(curr_data, expr_num, curr_calc, fs_method, est_name)\n",
    "                    f_features = [top_features[:n] for n in f_nums]\n",
    "                    elapsed.append(time.time() - start_time)\n",
    "                    print(elapsed[-1])\n",
    "\n",
    "                    for f_num, curr_f in zip(f_nums, f_features):\n",
    "                        curr_calc.calc_dist_simi_matrix(feature_names=curr_f)\n",
    "                        pen, pens = curr_calc.simi_penalty(n=knn_threshold)\n",
    "\n",
    "                        acc = 1 - (np.sum(pens)/(len(pens)*10))\n",
    "                        curr_accs.append(acc)\n",
    "                    all_accs.append(curr_accs)\n",
    "                all_accs = np.average(np.array(all_accs), axis=0)\n",
    "                for f_num, acc in zip(f_nums, all_accs):\n",
    "                    curr_method[f_num].append(acc)\n",
    "            main_dict[knn_threshold][f'{fs_method}_{est_name}'] = curr_method\n",
    "            time_dict[knn_threshold][f'{fs_method}_{est_name}'] = np.mean(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e149cc06-ae94-42b1-a70c-f6e9f186c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Forward_SFS_Linear\n",
      "545.5392210483551\n",
      "560.2021689414978\n",
      "590.7735526561737\n",
      "623.7616631984711\n",
      "Forward_SFS_DecisionTree\n",
      "675.3220210075378\n",
      "719.2019350528717\n",
      "734.5418281555176\n",
      "759.2209367752075\n",
      "Forward_SFS_LogisticRegression\n",
      "1761.1950585842133\n",
      "1817.3168053627014\n",
      "1847.6125705242157\n",
      "1892.8254897594452\n",
      "Backward_SFS_Linear\n",
      "2473.488553762436\n",
      "2688.293385028839\n",
      "2886.1261723041534\n",
      "3127.849019050598\n",
      "Backward_SFS_DecisionTree\n",
      "3417.977571249008\n",
      "3704.5509645938873\n",
      "4065.6282699108124\n",
      "4726.674874782562\n",
      "Backward_SFS_LogisticRegression\n",
      "7460.121118783951\n",
      "8485.44242477417\n",
      "14256.899272203445\n",
      "15331.577209234238\n",
      "2\n",
      "Forward_SFS_Linear\n",
      "7966.338711023331\n",
      "15715.799492359161\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m curr_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m f_features \u001b[38;5;241m=\u001b[39m [sfs_orders(curr_data, direction, est_name, n) \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m feature_num \u001b[38;5;28;01melse\u001b[39;00m all_features \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m f_nums]\n\u001b[1;32m     31\u001b[0m elapsed\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(elapsed[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[25], line 30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m curr_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m f_features \u001b[38;5;241m=\u001b[39m [\u001b[43msfs_orders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m feature_num \u001b[38;5;28;01melse\u001b[39;00m all_features \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m f_nums]\n\u001b[1;32m     31\u001b[0m elapsed\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(elapsed[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m, in \u001b[0;36msfs_orders\u001b[0;34m(curr_data, direction, est_name, n)\u001b[0m\n\u001b[1;32m     10\u001b[0m estimator \u001b[38;5;241m=\u001b[39m get_est(est_name)\n\u001b[1;32m     12\u001b[0m selector \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(estimator, direction\u001b[38;5;241m=\u001b[39mdirection\u001b[38;5;241m.\u001b[39mlower(), n_features_to_select\u001b[38;5;241m=\u001b[39mn, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m selector \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m mask \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mget_support()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features):\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/feature_selection/_sequential.py:251\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 251\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/feature_selection/_sequential.py:282\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    281\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 282\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    290\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:714\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    712\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 714\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 425\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/parallel.py:1846\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend:\n\u001b[0;32m-> 1846\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1848\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_effective_n_jobs()\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/parallel.py:1324\u001b[0m, in \u001b[0;36mParallel._initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1324\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39msupports_timeout:\n\u001b[1;32m   1327\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe backend class \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not support timeout. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in Parallel but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter will not be used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1331\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m   1332\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/_parallel_backends.py:550\u001b[0m, in \u001b[0;36mLokyBackend.configure\u001b[0;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FallbackToBackend(\n\u001b[1;32m    548\u001b[0m         SequentialBackend(nesting_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesting_level))\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midle_worker_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_worker_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmemmappingexecutor_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel \u001b[38;5;241m=\u001b[39m parallel\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_jobs\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/executor.py:20\u001b[0m, in \u001b[0;36mget_memmapping_executor\u001b[0;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memmapping_executor\u001b[39m(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMemmappingExecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/executor.py:69\u001b[0m, in \u001b[0;36mMemmappingExecutor.get_memmapping_executor\u001b[0;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     _executor\u001b[38;5;241m.\u001b[39m_temp_folder_manager \u001b[38;5;241m=\u001b[39m manager\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Only register the specified context once we know which manager\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# the current executor is using, in order to not register an atexit\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# finalizer twice for the same folder.\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temp_folder_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_new_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _executor\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:561\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.register_new_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# During its lifecycle, one Parallel object can have several\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# executors associated to it (for instance, if a loky worker raises\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;66;03m# to the current Manager (and thus specific to its associated\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# executor) to the folder name.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     new_folder_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib_memmapping_folder_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    559\u001b[0m             os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, context_id)\n\u001b[1;32m    560\u001b[0m     )\n\u001b[0;32m--> 561\u001b[0m     new_folder_path, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_temp_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_folder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temp_folder_root\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_folder_finalizer(new_folder_path, context_id)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_temp_folders[context_id] \u001b[38;5;241m=\u001b[39m new_folder_path\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:206\u001b[0m, in \u001b[0;36m_get_temp_dir\u001b[0;34m(pool_folder_name, temp_folder)\u001b[0m\n\u001b[1;32m    204\u001b[0m     temp_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJOBLIB_TEMP_FOLDER\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSYSTEM_SHARED_MEM_FS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatvfs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m             shm_stats \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstatvfs(SYSTEM_SHARED_MEM_FS)\n",
      "File \u001b[0;32m~/anaconda3/envs/workload_insights/lib/python3.9/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for knn_threshold in knn_thresholds:\n",
    "    print(knn_threshold)\n",
    "    \n",
    "    if knn_threshold not in main_dict:\n",
    "        main_dict[knn_threshold] = {}\n",
    "        time_dict[knn_threshold] = {}\n",
    "\n",
    "    fs_method = 'SFS'\n",
    "    for direction in ['Forward', 'Backward']:\n",
    "        for est_name in estimator_names:\n",
    "            print(direction+'_'+fs_method+'_'+est_name)\n",
    "            curr_method = {}\n",
    "\n",
    "            for f_num in f_nums:\n",
    "                curr_method[f_num] = []\n",
    "            elapsed = []\n",
    "            for sku in data_by_sku.keys():    \n",
    "                if 'ter' in sku:\n",
    "                    continue\n",
    "                curr_data = data_by_sku[sku]\n",
    "                curr_calc = data_dist[sku]\n",
    "                expr_num = curr_data.get_num_exprs()\n",
    "\n",
    "                all_accs = []\n",
    "                # run 10 times to get the average\n",
    "                num_repeats = 1\n",
    "                for i in range(num_repeats):       \n",
    "                    curr_accs = []\n",
    "                    start_time = time.time()\n",
    "                    f_features = [sfs_orders(curr_data, direction, est_name, n) if n < feature_num else all_features for n in f_nums]\n",
    "                    elapsed.append(time.time() - start_time)\n",
    "                    print(elapsed[-1])\n",
    "\n",
    "                    for f_num, curr_f in zip(f_nums, f_features):\n",
    "                        curr_calc.calc_dist_simi_matrix(feature_names=curr_f)\n",
    "                        pen, pens = curr_calc.simi_penalty(n=knn_threshold)\n",
    "\n",
    "                        acc = 1 - (np.sum(pens)/(len(pens)*10))\n",
    "                        curr_accs.append(acc)\n",
    "                    all_accs.append(curr_accs)\n",
    "                all_accs = np.average(np.array(all_accs), axis=0)\n",
    "                for f_num, acc in zip(f_nums, all_accs):\n",
    "                    curr_method[f_num].append(acc)\n",
    "            main_dict[knn_threshold][direction+'_'+fs_method+'_'+est_name] = curr_method\n",
    "            time_dict[knn_threshold][direction+'_'+fs_method+'_'+est_name] = np.mean(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bb1e2bd-bdad-470c-aebe-791f922d105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "method = Variance\n",
      "1 [0.4833333333333333, 0.24722222222222223, 0.24722222222222223, 0.25]\n",
      "3 [0.7166666666666667, 0.7861111111111111, 0.625, 0.6805555555555556]\n",
      "7 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = fANOVA\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9833333333333332, 0.9444444444444444, 0.9555555555555555, 0.9944444444444445]\n",
      "7 [0.986111111111111, 0.9527777777777777, 0.9805555555555555, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9888888888888889, 0.9833333333333332, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Chi2\n",
      "1 [0.4833333333333333, 0.4833333333333333, 0.4833333333333333, 0.7305555555555556]\n",
      "3 [0.9694444444444444, 0.95, 0.961111111111111, 0.7361111111111112]\n",
      "7 [0.9888888888888889, 0.9555555555555555, 0.9527777777777777, 0.9777777777777776]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = MutualInfoGain\n",
      "1 [0.9761111111111112, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9722222222222221, 0.9444444444444444, 0.9555555555555555, 0.9716666666666667]\n",
      "7 [0.986111111111111, 0.9888888888888889, 0.9877777777777779, 0.9916666666666668]\n",
      "15 [0.986111111111111, 0.9922222222222222, 0.9933333333333334, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Pearson\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9833333333333332, 0.9444444444444444, 0.9555555555555555, 0.9944444444444445]\n",
      "7 [0.986111111111111, 0.9527777777777777, 0.9805555555555555, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9833333333333332, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Lasso\n",
      "1 [0.6677777777777778, 0.9472222222222222, 0.9527777777777777, 0.7727777777777778]\n",
      "3 [0.9694444444444444, 0.9472222222222222, 0.961111111111111, 0.9722222222222221]\n",
      "7 [0.9777777777777776, 0.9738888888888889, 0.9716666666666667, 0.99]\n",
      "15 [0.9972222222222221, 0.9972222222222221, 0.9944444444444445, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Ridge\n",
      "1 [0.8833333333333332, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9916666666666668, 0.986111111111111, 0.975, 0.9944444444444445]\n",
      "7 [0.9916666666666668, 0.9944444444444445, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9944444444444445, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_Linear\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9722222222222221, 0.9555555555555555, 0.9777777777777776, 0.975]\n",
      "7 [0.9694444444444444, 0.9972222222222221, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9944444444444445, 0.9888888888888889]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_DecisionTree\n",
      "1 [0.24722222222222223, 0.24722222222222223, 0.24722222222222223, 0.25]\n",
      "3 [0.9527777777777777, 0.9944444444444445, 0.9416666666666667, 0.9888888888888889]\n",
      "7 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_LogisticRegression\n",
      "1 [0.9694444444444444, 0.725, 0.7305555555555556, 0.7305555555555556]\n",
      "3 [0.9694444444444444, 0.9555555555555555, 0.961111111111111, 0.975]\n",
      "7 [0.9888888888888889, 0.9916666666666668, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Forward_SFS_Linear\n",
      "1 [0.725, 0.6888888888888889, 0.6944444444444444, 0.6388888888888888]\n",
      "3 [0.9694444444444444, 0.9305555555555556, 0.9361111111111111, 0.9083333333333333]\n",
      "7 [0.9694444444444444, 0.9277777777777778, 0.9416666666666667, 0.9083333333333333]\n",
      "15 [0.9722222222222222, 0.9527777777777777, 0.9583333333333334, 0.9694444444444444]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "method = Forward_SFS_DecisionTree\n",
      "1 [0.725, 0.6888888888888889, 0.6944444444444444, 0.6388888888888888]\n",
      "3 [0.9694444444444444, 0.9305555555555556, 0.9361111111111111, 0.9083333333333333]\n",
      "7 [0.9694444444444444, 0.9277777777777778, 0.9416666666666667, 0.9083333333333333]\n",
      "15 [0.9722222222222222, 0.9527777777777777, 0.9583333333333334, 0.9694444444444444]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "method = Forward_SFS_LogisticRegression\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9722222222222222, 0.9444444444444444, 0.9555555555555556, 0.9694444444444444]\n",
      "7 [0.9722222222222222, 0.9527777777777777, 0.9583333333333334, 0.9694444444444444]\n",
      "15 [0.9722222222222222, 0.9527777777777777, 0.9583333333333334, 0.9694444444444444]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "method = Backward_SFS_Linear\n",
      "1 [0.24722222222222223, 0.24722222222222223, 0.24722222222222223, 0.25]\n",
      "3 [0.9527777777777777, 0.9944444444444445, 0.9416666666666667, 0.9888888888888889]\n",
      "7 [0.9972222222222222, 0.9944444444444445, 0.9972222222222222, 0.9972222222222222]\n",
      "15 [0.9972222222222222, 0.9944444444444445, 0.9972222222222222, 0.9972222222222222]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "method = Backward_SFS_DecisionTree\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9527777777777777, 0.9944444444444445, 0.9416666666666667, 0.9888888888888889]\n",
      "7 [0.9972222222222222, 0.9944444444444445, 0.9972222222222222, 0.9972222222222222]\n",
      "15 [0.9972222222222222, 0.9944444444444445, 0.9972222222222222, 0.9972222222222222]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "method = Backward_SFS_LogisticRegression\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9777777777777777, 0.9611111111111111, 0.9694444444444444, 0.9805555555555555]\n",
      "7 [0.9916666666666667, 0.9916666666666667, 0.9972222222222222, 0.9944444444444445]\n",
      "15 [0.9972222222222222, 0.9944444444444445, 0.9972222222222222, 0.9972222222222222]\n",
      "29 [0.9944444444444445, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "k = 2\n",
      "method = Variance\n",
      "1 [0.4833333333333333, 0.24722222222222223, 0.24722222222222223, 0.25]\n",
      "3 [0.7166666666666667, 0.7861111111111111, 0.625, 0.6805555555555556]\n",
      "7 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = fANOVA\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9833333333333332, 0.9444444444444444, 0.9555555555555555, 0.9944444444444445]\n",
      "7 [0.986111111111111, 0.9527777777777777, 0.9805555555555555, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9888888888888889, 0.9833333333333332, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Chi2\n",
      "1 [0.4833333333333333, 0.4833333333333333, 0.4833333333333333, 0.7305555555555556]\n",
      "3 [0.9694444444444444, 0.95, 0.961111111111111, 0.7361111111111112]\n",
      "7 [0.9888888888888889, 0.9555555555555555, 0.9527777777777777, 0.9777777777777776]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = MutualInfoGain\n",
      "1 [0.9805555555555555, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9722222222222221, 0.9444444444444444, 0.9555555555555555, 0.9694444444444444]\n",
      "7 [0.986111111111111, 0.9888888888888889, 0.9844444444444445, 0.9916666666666668]\n",
      "15 [0.9855555555555556, 0.9922222222222222, 0.9916666666666668, 0.9894444444444446]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Pearson\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9833333333333332, 0.9444444444444444, 0.9555555555555555, 0.9944444444444445]\n",
      "7 [0.986111111111111, 0.9527777777777777, 0.9805555555555555, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9833333333333332, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Lasso\n",
      "1 [0.7683333333333333, 0.9472222222222222, 0.9527777777777777, 0.5705555555555556]\n",
      "3 [0.9694444444444444, 0.9472222222222222, 0.961111111111111, 0.9722222222222221]\n",
      "7 [0.9777777777777776, 0.9738888888888889, 0.9716666666666667, 0.99]\n",
      "15 [0.9972222222222221, 0.9972222222222221, 0.9944444444444445, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = Ridge\n",
      "1 [0.8833333333333332, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9916666666666668, 0.986111111111111, 0.975, 0.9944444444444445]\n",
      "7 [0.9916666666666668, 0.9944444444444445, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9944444444444445, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_Linear\n",
      "1 [0.9694444444444444, 0.9472222222222222, 0.9527777777777777, 0.975]\n",
      "3 [0.9722222222222221, 0.9555555555555555, 0.9777777777777776, 0.975]\n",
      "7 [0.9694444444444444, 0.9972222222222221, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9888888888888889, 0.9944444444444445, 0.9944444444444445, 0.9888888888888889]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_DecisionTree\n",
      "1 [0.24722222222222223, 0.24722222222222223, 0.24722222222222223, 0.25]\n",
      "3 [0.9527777777777777, 0.9944444444444445, 0.9416666666666667, 0.9888888888888889]\n",
      "7 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "method = RFE_LogisticRegression\n",
      "1 [0.9694444444444444, 0.725, 0.7305555555555556, 0.7305555555555556]\n",
      "3 [0.9694444444444444, 0.9555555555555555, 0.961111111111111, 0.975]\n",
      "7 [0.9888888888888889, 0.9916666666666668, 0.9972222222222221, 0.9944444444444445]\n",
      "15 [0.9972222222222221, 0.9944444444444445, 0.9972222222222221, 0.9972222222222221]\n",
      "29 [0.9944444444444445, 0.9972222222222221, 0.9972222222222221, 0.9972222222222221]\n",
      "k = 3\n",
      "method = Variance\n",
      "1 [0.4833333333333333, 0.2416666666666667, 0.2416666666666667, 0.45]\n",
      "3 [0.7166666666666667, 0.7805555555555556, 0.6194444444444445, 0.6722222222222223]\n",
      "7 [0.9916666666666668, 0.9888888888888889, 0.9916666666666668, 0.9916666666666668]\n",
      "15 [0.9944444444444445, 0.9916666666666668, 0.9916666666666668, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = fANOVA\n",
      "1 [0.9583333333333334, 0.9527777777777777, 0.95, 0.9527777777777777]\n",
      "3 [0.9777777777777776, 0.95, 0.9527777777777777, 0.986111111111111]\n",
      "7 [0.9805555555555555, 0.9527777777777777, 0.975, 0.986111111111111]\n",
      "15 [0.9888888888888889, 0.9305555555555556, 0.9833333333333332, 0.986111111111111]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = Chi2\n",
      "1 [0.4833333333333333, 0.4833333333333333, 0.4833333333333333, 0.725]\n",
      "3 [0.9527777777777777, 0.9555555555555555, 0.9555555555555555, 0.7305555555555556]\n",
      "7 [0.9722222222222221, 0.9555555555555555, 0.95, 0.9527777777777777]\n",
      "15 [0.9944444444444445, 0.9916666666666668, 0.9916666666666668, 0.9944444444444445]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = MutualInfoGain\n",
      "1 [0.9694444444444444, 0.9527777777777777, 0.95, 0.9527777777777777]\n",
      "3 [0.9583333333333334, 0.95, 0.9544444444444442, 0.9472222222222222]\n",
      "7 [0.9805555555555555, 0.9305555555555556, 0.9766666666666666, 0.986111111111111]\n",
      "15 [0.9794444444444445, 0.9405555555555557, 0.9838888888888888, 0.9850000000000001]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = Pearson\n",
      "1 [0.9583333333333334, 0.9527777777777777, 0.95, 0.9527777777777777]\n",
      "3 [0.9777777777777776, 0.95, 0.9527777777777777, 0.986111111111111]\n",
      "7 [0.9805555555555555, 0.9527777777777777, 0.975, 0.986111111111111]\n",
      "15 [0.9888888888888889, 0.9888888888888889, 0.9833333333333332, 0.986111111111111]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = Lasso\n",
      "1 [0.7616666666666667, 0.9527777777777777, 0.95, 0.6627777777777778]\n",
      "3 [0.9583333333333334, 0.9527777777777777, 0.9555555555555555, 0.95]\n",
      "7 [0.961111111111111, 0.96, 0.9638888888888889, 0.9794444444444445]\n",
      "15 [0.9944444444444445, 0.9916666666666668, 0.9916666666666668, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = Ridge\n",
      "1 [0.8, 0.9527777777777777, 0.95, 0.9527777777777777]\n",
      "3 [0.9888888888888889, 0.9805555555555555, 0.975, 0.986111111111111]\n",
      "7 [0.9888888888888889, 0.9916666666666668, 0.9916666666666668, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9888888888888889, 0.986111111111111, 0.9944444444444445]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = RFE_Linear\n",
      "1 [0.9583333333333334, 0.9527777777777777, 0.95, 0.9527777777777777]\n",
      "3 [0.961111111111111, 0.9555555555555555, 0.9722222222222221, 0.9666666666666666]\n",
      "7 [0.961111111111111, 0.9916666666666668, 0.9888888888888889, 0.9916666666666668]\n",
      "15 [0.9888888888888889, 0.9888888888888889, 0.986111111111111, 0.9916666666666668]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = RFE_DecisionTree\n",
      "1 [0.24722222222222223, 0.2416666666666667, 0.2416666666666667, 0.45]\n",
      "3 [0.9444444444444444, 0.8777777777777779, 0.9361111111111111, 0.9833333333333332]\n",
      "7 [0.9916666666666668, 0.9722222222222221, 0.9916666666666668, 0.9944444444444445]\n",
      "15 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n",
      "method = RFE_LogisticRegression\n",
      "1 [0.9583333333333334, 0.725, 0.7277777777777779, 0.725]\n",
      "3 [0.9527777777777777, 0.9555555555555555, 0.9555555555555555, 0.9583333333333334]\n",
      "7 [0.9722222222222221, 0.9333333333333333, 0.986111111111111, 0.986111111111111]\n",
      "15 [0.9944444444444445, 0.9916666666666668, 0.9916666666666668, 0.9944444444444445]\n",
      "29 [0.9944444444444445, 0.9916666666666668, 0.9944444444444445, 0.9944444444444445]\n"
     ]
    }
   ],
   "source": [
    "for key, val in main_dict.items():\n",
    "    print(f'k = {key}')\n",
    "    for subk, subval in val.items():\n",
    "        print(f'method = {subk}')\n",
    "        for fnum, subsubval in subval.items():\n",
    "            print(fnum, subsubval)\n",
    "# print(main_dict[knn_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a1fe982-ed5b-41a4-985e-c045497189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_table(k=3, sku=None):\n",
    "    name_trans_dict = {\n",
    "        'Forward_SFS_Linear': 'Fw SFS Linear',\n",
    "        'Backward_SFS_Linear': 'Bw SFS Linear',\n",
    "        'Forward_SFS_DecisionTree': 'Fw SFS DecTree',\n",
    "        'Backward_SFS_DecisionTree': 'Bw SFS DecTree',\n",
    "        'Forward_SFS_LogisticRegression': 'Fw SFS LogReg',\n",
    "        'Backward_SFS_LogisticRegression': 'Bw SFS LogReg',\n",
    "        'MutualInfoGain': 'MIGain',\n",
    "        'RFE_Linear': 'RFE Linear',\n",
    "        'RFE_DecisionTree': 'RFE DecTree',\n",
    "        'RFE_LogisticRegression': 'RFE LogReg',\n",
    "    }\n",
    "    \n",
    "    sku_trans_dict = {\n",
    "        'cpu2': 0,\n",
    "        'cpu4': 1,\n",
    "        'cpu8': 2,\n",
    "        'cpu16': 3,\n",
    "    }\n",
    "    \n",
    "    for method, subval in main_dict[k].items():\n",
    "        outstr = '\\\\textcolor{}{'\n",
    "        print_name = method if method not in name_trans_dict else name_trans_dict[method]\n",
    "        outstr += print_name\n",
    "        outstr += '} & '\n",
    "        for fnum, subsubval in subval.items():\n",
    "            if fnum == 29:\n",
    "                continue\n",
    "            if sku is None:\n",
    "                outstr += f'{np.mean(subsubval):.3f} & '\n",
    "            else:\n",
    "                outstr += f'{subsubval[sku_trans_dict[sku]]:.3f} & '\n",
    "        if method == 'Variance':\n",
    "            if sku is None:\n",
    "                all_acc = np.mean(subval[29])\n",
    "            else:\n",
    "                all_acc = subval[29][sku_trans_dict[sku]]\n",
    "            outstr += '\\multirow{17}{*}{'\n",
    "            outstr += '{:.3f}'.format(all_acc)\n",
    "            outstr += '}'\n",
    "        outstr += f' & {time_dict[k][method]:.3f} \\\\\\\\'\n",
    "        print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9db1198-2ede-4d7a-97ce-8cffb0338d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.307 & 0.702 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.020 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.961 & 0.969 & 0.978 & 0.988 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.545 & 0.904 & 0.969 & 0.997 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.963 & 0.961 & 0.989 & 0.991 &  & 2.403 \\\\\n",
      "\\textcolor{}{Pearson} & 0.961 & 0.969 & 0.978 & 0.990 &  & 0.030 \\\\\n",
      "\\textcolor{}{Lasso} & 0.835 & 0.962 & 0.978 & 0.997 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.940 & 0.987 & 0.994 & 0.994 &  & 0.051 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.961 & 0.970 & 0.990 & 0.992 &  & 1.128 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.248 & 0.969 & 0.997 & 0.997 &  & 1.202 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.789 & 0.965 & 0.993 & 0.997 &  & 18.936 \\\\\n",
      "\\textcolor{}{Fw SFS Linear} & 0.687 & 0.936 & 0.937 & 0.963 &  & 580.069 \\\\\n",
      "\\textcolor{}{Fw SFS DecTree} & 0.687 & 0.936 & 0.937 & 0.963 &  & 722.072 \\\\\n",
      "\\textcolor{}{Fw SFS LogReg} & 0.961 & 0.960 & 0.963 & 0.963 &  & 1829.737 \\\\\n",
      "\\textcolor{}{Bw SFS Linear} & 0.248 & 0.969 & 0.997 & 0.997 &  & 2793.939 \\\\\n",
      "\\textcolor{}{Bw SFS DecTree} & 0.961 & 0.969 & 0.997 & 0.997 &  & 3978.708 \\\\\n",
      "\\textcolor{}{Bw SFS LogReg} & 0.961 & 0.972 & 0.994 & 0.997 &  & 11383.510 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.997 & 0.997 & \\multirow{17}{*}{0.994} & 0.020 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.969 & 0.989 & 0.997 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.976 & 0.972 & 0.986 & 0.986 &  & 2.403 \\\\\n",
      "\\textcolor{}{Pearson} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.030 \\\\\n",
      "\\textcolor{}{Lasso} & 0.668 & 0.969 & 0.978 & 0.997 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.883 & 0.992 & 0.992 & 0.989 &  & 0.051 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.969 & 0.972 & 0.969 & 0.989 &  & 1.128 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.953 & 0.997 & 0.997 &  & 1.202 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.969 & 0.969 & 0.989 & 0.997 &  & 18.936 \\\\\n",
      "\\textcolor{}{Fw SFS Linear} & 0.725 & 0.969 & 0.969 & 0.972 &  & 580.069 \\\\\n",
      "\\textcolor{}{Fw SFS DecTree} & 0.725 & 0.969 & 0.969 & 0.972 &  & 722.072 \\\\\n",
      "\\textcolor{}{Fw SFS LogReg} & 0.969 & 0.972 & 0.972 & 0.972 &  & 1829.737 \\\\\n",
      "\\textcolor{}{Bw SFS Linear} & 0.247 & 0.953 & 0.997 & 0.997 &  & 2793.939 \\\\\n",
      "\\textcolor{}{Bw SFS DecTree} & 0.969 & 0.953 & 0.997 & 0.997 &  & 3978.708 \\\\\n",
      "\\textcolor{}{Bw SFS LogReg} & 0.969 & 0.978 & 0.992 & 0.997 &  & 11383.510 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.786 & 0.994 & 0.994 & \\multirow{17}{*}{0.997} & 0.020 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.947 & 0.944 & 0.953 & 0.989 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.950 & 0.956 & 0.994 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.947 & 0.944 & 0.989 & 0.992 &  & 2.403 \\\\\n",
      "\\textcolor{}{Pearson} & 0.947 & 0.944 & 0.953 & 0.994 &  & 0.030 \\\\\n",
      "\\textcolor{}{Lasso} & 0.947 & 0.947 & 0.974 & 0.997 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.947 & 0.986 & 0.994 & 0.994 &  & 0.051 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.947 & 0.956 & 0.997 & 0.994 &  & 1.128 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.994 & 0.994 & 0.994 &  & 1.202 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.725 & 0.956 & 0.992 & 0.994 &  & 18.936 \\\\\n",
      "\\textcolor{}{Fw SFS Linear} & 0.689 & 0.931 & 0.928 & 0.953 &  & 580.069 \\\\\n",
      "\\textcolor{}{Fw SFS DecTree} & 0.689 & 0.931 & 0.928 & 0.953 &  & 722.072 \\\\\n",
      "\\textcolor{}{Fw SFS LogReg} & 0.947 & 0.944 & 0.953 & 0.953 &  & 1829.737 \\\\\n",
      "\\textcolor{}{Bw SFS Linear} & 0.247 & 0.994 & 0.994 & 0.994 &  & 2793.939 \\\\\n",
      "\\textcolor{}{Bw SFS DecTree} & 0.947 & 0.994 & 0.994 & 0.994 &  & 3978.708 \\\\\n",
      "\\textcolor{}{Bw SFS LogReg} & 0.947 & 0.961 & 0.992 & 0.994 &  & 11383.510 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.625 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.020 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.961 & 0.953 & 0.997 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.956 & 0.988 & 0.993 &  & 2.403 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.030 \\\\\n",
      "\\textcolor{}{Lasso} & 0.953 & 0.961 & 0.972 & 0.994 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.953 & 0.975 & 0.997 & 0.994 &  & 0.051 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.953 & 0.978 & 0.997 & 0.994 &  & 1.128 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.942 & 0.997 & 0.997 &  & 1.202 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.731 & 0.961 & 0.997 & 0.997 &  & 18.936 \\\\\n",
      "\\textcolor{}{Fw SFS Linear} & 0.694 & 0.936 & 0.942 & 0.958 &  & 580.069 \\\\\n",
      "\\textcolor{}{Fw SFS DecTree} & 0.694 & 0.936 & 0.942 & 0.958 &  & 722.072 \\\\\n",
      "\\textcolor{}{Fw SFS LogReg} & 0.953 & 0.956 & 0.958 & 0.958 &  & 1829.737 \\\\\n",
      "\\textcolor{}{Bw SFS Linear} & 0.247 & 0.942 & 0.997 & 0.997 &  & 2793.939 \\\\\n",
      "\\textcolor{}{Bw SFS DecTree} & 0.953 & 0.942 & 0.997 & 0.997 &  & 3978.708 \\\\\n",
      "\\textcolor{}{Bw SFS LogReg} & 0.953 & 0.969 & 0.997 & 0.997 &  & 11383.510 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.250 & 0.681 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.020 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.731 & 0.736 & 0.978 & 0.997 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.975 & 0.972 & 0.992 & 0.992 &  & 2.403 \\\\\n",
      "\\textcolor{}{Pearson} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.030 \\\\\n",
      "\\textcolor{}{Lasso} & 0.773 & 0.972 & 0.990 & 0.997 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.975 & 0.994 & 0.994 & 0.997 &  & 0.051 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.975 & 0.975 & 0.994 & 0.989 &  & 1.128 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.250 & 0.989 & 0.997 & 0.997 &  & 1.202 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.731 & 0.975 & 0.994 & 0.997 &  & 18.936 \\\\\n",
      "\\textcolor{}{Fw SFS Linear} & 0.639 & 0.908 & 0.908 & 0.969 &  & 580.069 \\\\\n",
      "\\textcolor{}{Fw SFS DecTree} & 0.639 & 0.908 & 0.908 & 0.969 &  & 722.072 \\\\\n",
      "\\textcolor{}{Fw SFS LogReg} & 0.975 & 0.969 & 0.969 & 0.969 &  & 1829.737 \\\\\n",
      "\\textcolor{}{Bw SFS Linear} & 0.250 & 0.989 & 0.997 & 0.997 &  & 2793.939 \\\\\n",
      "\\textcolor{}{Bw SFS DecTree} & 0.975 & 0.989 & 0.997 & 0.997 &  & 3978.708 \\\\\n",
      "\\textcolor{}{Bw SFS LogReg} & 0.975 & 0.981 & 0.994 & 0.997 &  & 11383.510 \\\\\n",
      "2 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.307 & 0.702 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.023 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.961 & 0.969 & 0.978 & 0.988 &  & 0.042 \\\\\n",
      "\\textcolor{}{Chi2} & 0.545 & 0.904 & 0.969 & 0.997 &  & 0.060 \\\\\n",
      "\\textcolor{}{MIGain} & 0.964 & 0.960 & 0.988 & 0.990 &  & 2.238 \\\\\n",
      "\\textcolor{}{Pearson} & 0.961 & 0.969 & 0.978 & 0.990 &  & 0.028 \\\\\n",
      "\\textcolor{}{Lasso} & 0.810 & 0.962 & 0.978 & 0.997 &  & 0.048 \\\\\n",
      "\\textcolor{}{Ridge} & 0.940 & 0.987 & 0.994 & 0.994 &  & 0.048 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.961 & 0.970 & 0.990 & 0.992 &  & 1.135 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.248 & 0.969 & 0.997 & 0.997 &  & 1.211 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.789 & 0.965 & 0.993 & 0.997 &  & 19.588 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.997 & 0.997 & \\multirow{17}{*}{0.994} & 0.023 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.042 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.969 & 0.989 & 0.997 &  & 0.060 \\\\\n",
      "\\textcolor{}{MIGain} & 0.981 & 0.972 & 0.986 & 0.986 &  & 2.238 \\\\\n",
      "\\textcolor{}{Pearson} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.028 \\\\\n",
      "\\textcolor{}{Lasso} & 0.768 & 0.969 & 0.978 & 0.997 &  & 0.048 \\\\\n",
      "\\textcolor{}{Ridge} & 0.883 & 0.992 & 0.992 & 0.989 &  & 0.048 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.969 & 0.972 & 0.969 & 0.989 &  & 1.135 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.953 & 0.997 & 0.997 &  & 1.211 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.969 & 0.969 & 0.989 & 0.997 &  & 19.588 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.786 & 0.994 & 0.994 & \\multirow{17}{*}{0.997} & 0.023 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.947 & 0.944 & 0.953 & 0.989 &  & 0.042 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.950 & 0.956 & 0.994 &  & 0.060 \\\\\n",
      "\\textcolor{}{MIGain} & 0.947 & 0.944 & 0.989 & 0.992 &  & 2.238 \\\\\n",
      "\\textcolor{}{Pearson} & 0.947 & 0.944 & 0.953 & 0.994 &  & 0.028 \\\\\n",
      "\\textcolor{}{Lasso} & 0.947 & 0.947 & 0.974 & 0.997 &  & 0.048 \\\\\n",
      "\\textcolor{}{Ridge} & 0.947 & 0.986 & 0.994 & 0.994 &  & 0.048 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.947 & 0.956 & 0.997 & 0.994 &  & 1.135 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.994 & 0.994 & 0.994 &  & 1.211 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.725 & 0.956 & 0.992 & 0.994 &  & 19.588 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.625 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.023 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.042 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.961 & 0.953 & 0.997 &  & 0.060 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.956 & 0.984 & 0.992 &  & 2.238 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.028 \\\\\n",
      "\\textcolor{}{Lasso} & 0.953 & 0.961 & 0.972 & 0.994 &  & 0.048 \\\\\n",
      "\\textcolor{}{Ridge} & 0.953 & 0.975 & 0.997 & 0.994 &  & 0.048 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.953 & 0.978 & 0.997 & 0.994 &  & 1.135 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.942 & 0.997 & 0.997 &  & 1.211 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.731 & 0.961 & 0.997 & 0.997 &  & 19.588 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.250 & 0.681 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.023 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.042 \\\\\n",
      "\\textcolor{}{Chi2} & 0.731 & 0.736 & 0.978 & 0.997 &  & 0.060 \\\\\n",
      "\\textcolor{}{MIGain} & 0.975 & 0.969 & 0.992 & 0.989 &  & 2.238 \\\\\n",
      "\\textcolor{}{Pearson} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.028 \\\\\n",
      "\\textcolor{}{Lasso} & 0.571 & 0.972 & 0.990 & 0.997 &  & 0.048 \\\\\n",
      "\\textcolor{}{Ridge} & 0.975 & 0.994 & 0.994 & 0.997 &  & 0.048 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.975 & 0.975 & 0.994 & 0.989 &  & 1.135 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.250 & 0.989 & 0.997 & 0.997 &  & 1.211 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.731 & 0.975 & 0.994 & 0.997 &  & 19.588 \\\\\n",
      "3 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.354 & 0.697 & 0.991 & 0.992 & \\multirow{17}{*}{0.994} & 0.021 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.967 & 0.974 & 0.972 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.544 & 0.899 & 0.958 & 0.993 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.956 & 0.952 & 0.968 & 0.972 &  & 2.218 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.967 & 0.974 & 0.987 &  & 0.029 \\\\\n",
      "\\textcolor{}{Lasso} & 0.832 & 0.954 & 0.966 & 0.992 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.914 & 0.983 & 0.991 & 0.990 &  & 0.050 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.953 & 0.964 & 0.983 & 0.989 &  & 1.185 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.295 & 0.935 & 0.988 & 0.994 &  & 1.181 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.784 & 0.956 & 0.969 & 0.993 &  & 21.464 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.992 & 0.994 & \\multirow{17}{*}{0.994} & 0.021 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.958 & 0.978 & 0.981 & 0.989 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.953 & 0.972 & 0.994 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.969 & 0.958 & 0.981 & 0.979 &  & 2.218 \\\\\n",
      "\\textcolor{}{Pearson} & 0.958 & 0.978 & 0.981 & 0.989 &  & 0.029 \\\\\n",
      "\\textcolor{}{Lasso} & 0.762 & 0.958 & 0.961 & 0.994 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.800 & 0.989 & 0.989 & 0.989 &  & 0.050 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.958 & 0.961 & 0.961 & 0.989 &  & 1.185 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.247 & 0.944 & 0.992 & 0.994 &  & 1.181 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.958 & 0.953 & 0.972 & 0.994 &  & 21.464 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.242 & 0.781 & 0.989 & 0.992 & \\multirow{17}{*}{0.992} & 0.021 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.950 & 0.953 & 0.931 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.956 & 0.956 & 0.992 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.950 & 0.931 & 0.941 &  & 2.218 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.950 & 0.953 & 0.989 &  & 0.029 \\\\\n",
      "\\textcolor{}{Lasso} & 0.953 & 0.953 & 0.960 & 0.992 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.953 & 0.981 & 0.992 & 0.989 &  & 0.050 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.953 & 0.956 & 0.992 & 0.989 &  & 1.185 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.242 & 0.878 & 0.972 & 0.992 &  & 1.181 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.725 & 0.956 & 0.933 & 0.992 &  & 21.464 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.242 & 0.619 & 0.992 & 0.992 & \\multirow{17}{*}{0.994} & 0.021 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.950 & 0.953 & 0.975 & 0.983 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.483 & 0.956 & 0.950 & 0.992 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.950 & 0.954 & 0.977 & 0.984 &  & 2.218 \\\\\n",
      "\\textcolor{}{Pearson} & 0.950 & 0.953 & 0.975 & 0.983 &  & 0.029 \\\\\n",
      "\\textcolor{}{Lasso} & 0.950 & 0.956 & 0.964 & 0.992 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.950 & 0.975 & 0.992 & 0.986 &  & 0.050 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.950 & 0.972 & 0.989 & 0.986 &  & 1.185 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.242 & 0.936 & 0.992 & 0.994 &  & 1.181 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.728 & 0.956 & 0.986 & 0.992 &  & 21.464 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.450 & 0.672 & 0.992 & 0.992 & \\multirow{17}{*}{0.994} & 0.021 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.986 & 0.986 & 0.986 &  & 0.040 \\\\\n",
      "\\textcolor{}{Chi2} & 0.725 & 0.731 & 0.953 & 0.994 &  & 0.062 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.947 & 0.986 & 0.985 &  & 2.218 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.986 & 0.986 & 0.986 &  & 0.029 \\\\\n",
      "\\textcolor{}{Lasso} & 0.663 & 0.950 & 0.979 & 0.992 &  & 0.049 \\\\\n",
      "\\textcolor{}{Ridge} & 0.953 & 0.986 & 0.992 & 0.994 &  & 0.050 \\\\\n",
      "\\textcolor{}{RFE Linear} & 0.953 & 0.967 & 0.992 & 0.992 &  & 1.185 \\\\\n",
      "\\textcolor{}{RFE DecTree} & 0.450 & 0.983 & 0.994 & 0.994 &  & 1.181 \\\\\n",
      "\\textcolor{}{RFE LogReg} & 0.725 & 0.958 & 0.986 & 0.994 &  & 21.464 \\\\\n"
     ]
    }
   ],
   "source": [
    "for k in [1,2,3]:\n",
    "    print(k, \"-----overall-----\")\n",
    "    pretty_print_table(k=k)\n",
    "    for sku in [f'cpu{num}' for num in [2, 4, 8, 16]]:\n",
    "        print(f\"-----{sku}-----\")\n",
    "        pretty_print_table(k=k, sku=sku)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload_insights",
   "language": "python",
   "name": "workload_insights"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
