{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ddc07ed-a9e1-4257-83ef-5b758666bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Copy for testing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import compress\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import lasso_path, enet_path, LogisticRegression, ElasticNet, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE, SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.feature_selection import f_classif, chi2, mutual_info_classif, r_regression\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from helpers import expr_data\n",
    "from helpers import scale_data\n",
    "from helpers import similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993a3523-c757-454a-8293-9aa28dcf34c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "SMALL_SMALL_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "\n",
    "plt.rc('legend', fontsize=SMALL_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f968ba-a705-4465-9926-e98a873af1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37663de8-c366-46b6-95ad-e0c5cbc432bf",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d781e6-951b-4f76-ab71-2fb8d5963c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = expr_data.ExprData()\n",
    "data.load_pickle()\n",
    "data = data.fix_tpch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f438a-632d-4486-bd01-deea57cd02fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split by SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbdbae2-b3b0-4309-8945-330f41be72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_sku = data.split_by_sku()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cc264-c8ee-4a29-b419-d668be0bd37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2a954-220e-4a39-8b69-30afe288e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result sku_result is a dict with its key the SKU,\n",
    "# the value a list, the classification accuracy for each f_num\n",
    "data_dist = {}\n",
    "\n",
    "for sku in data_by_sku.keys():\n",
    "    curr_data = data_by_sku[sku]\n",
    "    if 'ter' in sku:\n",
    "        continue\n",
    "    print(f'cpu_num={sku}')\n",
    "    scaler = scale_data.ScaleData()\n",
    "    plan_mtxs_splitted, plan_col_ranges = scaler.scale(curr_data.plan_mtxs)\n",
    "    perf_mtxs_splitted, perf_col_ranges = scaler.scale(curr_data.perf_mtxs)\n",
    "    simi_calc = similarity.Similarity(curr_data, plan_mtxs_splitted, plan_col_ranges, perf_mtxs_splitted, perf_col_ranges, num_bins=10)\n",
    "\n",
    "    simi_calc.calc_bined_mtx() # all features\n",
    "    simi_calc.calc_dist_simi_matrix(normalize=True)\n",
    "    print(simi_calc.simi_mtx.shape)\n",
    "    # feature wise distance\n",
    "    simi_calc.calc_featurewise_dist_by_col()\n",
    "    print(simi_calc.simi_col_mtx.shape)\n",
    "    \n",
    "    data_dist[sku] = simi_calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82729bef-d6fe-4137-97db-ac81ced0bc11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select Top K Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525bfc84-5958-495a-a2ff-2bde2ede6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return non-zero index in descending order\n",
    "def sparse_argsort(arr):\n",
    "    arr = np.where(np.isnan(arr), 0, arr)\n",
    "    arr = arr * -1\n",
    "    indices = np.nonzero(arr)[0]\n",
    "    result = indices[np.argsort(arr[indices])]\n",
    "    return result\n",
    "\n",
    "def all_argsort(arr):\n",
    "    arr = np.where(np.isnan(arr), 0, arr)\n",
    "    arr = arr * -1\n",
    "    result = np.argsort(arr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a46272-f1ec-4b10-857c-3550a72d29cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8819e-b7bb-4188-a4cb-fcc539bf9296",
   "metadata": {},
   "source": [
    "#### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003b606f-9b02-4594-852e-9ba6cbbc6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold(X, y):\n",
    "    selector = VarianceThreshold()\n",
    "    selector.fit(X)\n",
    "    scores = selector.variances_\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a01d8-ed86-408b-b6c1-1aa50f1b7215",
   "metadata": {},
   "source": [
    "#### fANOVA, Chi-Squared test, Mutual Information gain, Fisher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445c5fa9-527c-4470-ba14-45a3b85ddbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fANOVA, Chi-Squared test, Mutual Information gain, Fisher score\n",
    "def select_k_best(X, y, method):\n",
    "    if method == 'fANOVA':\n",
    "        selector = SelectKBest(f_classif, k='all')\n",
    "    elif method == 'Chi2':\n",
    "        selector = SelectKBest(chi2, k='all')\n",
    "    elif method == 'MutualInfoGain': \n",
    "        selector = SelectKBest(mutual_info_classif, k='all')  \n",
    "    elif method == 'Pearson': #https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.r_regression.htm\n",
    "        selector = SelectKBest(r_regression, k='all')  \n",
    "    selector.fit(X, y)\n",
    "    scores = np.absolute(selector.scores_)\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61fb0e0-c187-4a27-ad94-a38d07457468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide by zero; not using this\n",
    "def fisher_orders(X, y):\n",
    "    ranks = fisher_score.fisher_score(X, y, mode='rank')\n",
    "    # ranks are: 1 for most important\n",
    "    scores = -1 * ranks\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5c289-d4c4-4f00-a703-115dbe0fe124",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wrapper method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586c399-fcec-4073-8fcf-852ba206434c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RFE (Recursive feature elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710283bb-4b00-4ca8-a549-824995aec475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_est(est_name):\n",
    "    if est_name == 'DecisionTree':\n",
    "        estimator = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "    elif est_name == 'LogisticRegression':\n",
    "        estimator = LogisticRegression(n_jobs=-1, C=0.01) # C, tol, \n",
    "    else: # est_name == 'Linear':\n",
    "        estimator = SVR(kernel=\"linear\", C=0.05, ) # kernel, degree, \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a156a2bb-3b98-47f3-84f0-1ca63132e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create customize base estimator: https://stackoverflow.com/questions/51679173/using-sklearn-rfe-with-an-estimator-from-another-package\n",
    "def rfe_orders(X, y, est_name):\n",
    "    estimator = get_est(est_name)\n",
    "    selector = RFE(estimator, n_features_to_select=1, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "    # ranks are: 1 for most important\n",
    "    scores = -1 * selector.ranking_\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c6ebc-84f0-45a2-b14f-06a1186d38d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SFS (Sequential Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1056f5-b5d4-4ded-8014-42da886ef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfs_orders(curr_data, direction, est_name, n):\n",
    "    num_features = len(curr_data.feature_cols)\n",
    "    feature_importance = np.array([0]*num_features)\n",
    "    expr_num = curr_data.get_num_exprs()\n",
    "\n",
    "    for i in range(expr_num):\n",
    "        # calculate label\n",
    "        curr_name = curr_data.wl_names[i]\n",
    "        y = [curr_name == name for name in curr_data.wl_names]\n",
    "        X = simi_calc.simi_col_mtx[i]\n",
    "        estimator = get_est(est_name)\n",
    "\n",
    "        selector = SequentialFeatureSelector(estimator, direction=direction.lower(), n_features_to_select=n, n_jobs=-1, cv=3)\n",
    "        selector = selector.fit(X, y)\n",
    "        mask = selector.get_support()\n",
    "        for idx in range(num_features):\n",
    "            feature_importance[idx] += mask[idx]\n",
    "    final_orders = sparse_argsort(feature_importance)[:n]\n",
    "    top_features = [curr_data.feature_cols[j] for j in final_orders]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7ab6a-adf6-40dc-8984-218d926ba27d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedded method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808926e-b655-4f7e-a582-21baf08c8ac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48b55ea-aee2-4c7a-ad34-d16e5993f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_weights_orders(X, y):\n",
    "    selector = Lasso(alpha=0.1).fit(X, y) # C \n",
    "    scores = np.abs(selector.coef_)\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc6fd0-24e1-48c7-bc4d-a3163c9a0de8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0e4a70-9921-4b44-9c0b-95a6e38ea06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enet_weights_orders(X, y):\n",
    "    selector = ElasticNet(alpha=0.1, l1_ratio=0.4).fit(X, y)\n",
    "    scores = np.abs(selector.coef_)\n",
    "    return sparse_argsort(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce8a93-ffc5-4852-83e1-268ca1eb087a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature select main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5806b74d-8a98-4634-84fa-ad2a7bd6a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(curr_data, expr_num, simi_calc, method, note=None):\n",
    "\n",
    "    # create dict for all features\n",
    "    num_features = len(curr_data.feature_cols)\n",
    "    feature_importance = np.array([0]*num_features)\n",
    "    \n",
    "    for i in range(expr_num):\n",
    "        # calculate label\n",
    "        curr_name = curr_data.wl_names[i]\n",
    "        y = [curr_name == name for name in curr_data.wl_names]\n",
    "        X = simi_calc.simi_col_mtx[i]\n",
    "        \n",
    "        mask = np.ones(X.shape[0], dtype=bool)  \n",
    "        X = X[mask]#.reshape(-1, 1)\n",
    "                \n",
    "        if method == 'Lasso':\n",
    "            orders = lasso_weights_orders(X, y)\n",
    "        elif method == 'ENet':\n",
    "            orders = enet_weights_orders(X, y)\n",
    "        elif method == 'Variance':\n",
    "            orders = variance_threshold(X, y)\n",
    "        elif method == 'fANOVA':\n",
    "            orders = select_k_best(X, y, method='fANOVA')\n",
    "        elif method == 'Chi2':\n",
    "            orders = select_k_best(X, y, method='Chi2')\n",
    "        elif method == 'MutualInfoGain':\n",
    "            orders = select_k_best(X, y, method='MutualInfoGain')\n",
    "        elif method == 'Pearson':\n",
    "            orders = select_k_best(X, y, method='Pearson')\n",
    "        elif method == 'Fisher':\n",
    "            orders = fisher_orders(X, y)\n",
    "        elif method == 'RFE':\n",
    "            orders = rfe_orders(X, y, note)\n",
    "\n",
    "        for idx in range(len(orders)):\n",
    "            # from 0 to last idx of orders\n",
    "            # the score = num_features - idx\n",
    "            #   for a entry with feature_idx important order idx idx\n",
    "            # the higher the order, the more the score\n",
    "            feature_importance[orders[idx]] += num_features-idx\n",
    "    final_orders = all_argsort(feature_importance)\n",
    "    top_features = [curr_data.feature_cols[j] for j in final_orders]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aaeaf3-3190-4a44-a65e-8fb0dbd067c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare Feature Selection with Similarity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa76e37-9eef-48a0-a450-eb9ba846edc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf2cedaf-4df1-4d1f-be62-aa5879ee0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = {}\n",
    "time_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f588563-bde0-4c63-825d-f799d0fbe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data_by_sku[list(data_by_sku.keys())[0]].feature_cols\n",
    "feature_num = len(all_features)\n",
    "\n",
    "knn_thresholds = [1, 2, 3]\n",
    "direct_methods = ['Variance', 'fANOVA', 'MutualInfoGain', 'Pearson', 'Lasso', 'ENet']\n",
    "wrapper_methods = ['RFE']\n",
    "estimator_names = ['Linear', 'DecisionTree', 'LogisticRegression']\n",
    "other_methods = ['SFS', ]\n",
    "simi_method = 'KNN'\n",
    "\n",
    "f_nums = [1, 3, 7, 15, feature_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f44d0b4c-6956-40a8-ba82-585884704bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Variance\n",
      "0.03309154510498047\n",
      "fANOVA\n",
      "0.05154687166213989\n",
      "MutualInfoGain\n",
      "3.2459532618522644\n",
      "Pearson\n",
      "0.03456294536590576\n",
      "Lasso\n",
      "0.051907360553741455\n",
      "ENet\n",
      "0.09475409984588623\n",
      "2\n",
      "Variance\n",
      "0.024421095848083496\n",
      "fANOVA\n",
      "0.04363507032394409\n",
      "MutualInfoGain\n",
      "2.6107080578804016\n",
      "Pearson\n",
      "0.0350375771522522\n",
      "Lasso\n",
      "0.05205315351486206\n",
      "ENet\n",
      "0.10130876302719116\n",
      "3\n",
      "Variance\n",
      "0.0242387056350708\n",
      "fANOVA\n",
      "0.04818713665008545\n",
      "MutualInfoGain\n",
      "2.53963840007782\n",
      "Pearson\n",
      "0.03474068641662598\n",
      "Lasso\n",
      "0.05609309673309326\n",
      "ENet\n",
      "0.10970205068588257\n"
     ]
    }
   ],
   "source": [
    "for knn_threshold in knn_thresholds:\n",
    "    print(knn_threshold)\n",
    "    \n",
    "    if knn_threshold not in main_dict:\n",
    "        main_dict[knn_threshold] = {}\n",
    "        time_dict[knn_threshold] = {}\n",
    "    for fs_method in direct_methods:\n",
    "        print(fs_method)\n",
    "        curr_method = {}\n",
    "\n",
    "        for f_num in f_nums:\n",
    "            curr_method[f_num] = []\n",
    "        elapsed = []\n",
    "        for sku in data_by_sku.keys():    \n",
    "            if 'ter' in sku:\n",
    "                continue\n",
    "            curr_data = data_by_sku[sku]\n",
    "            curr_calc = data_dist[sku]\n",
    "            expr_num = curr_data.get_num_exprs()\n",
    "        \n",
    "            all_accs = []\n",
    "            num_repeats = 1\n",
    "            for i in range(num_repeats):       \n",
    "                curr_accs = []\n",
    "                start_time = time.time()\n",
    "                top_features = get_top_features(curr_data, expr_num, curr_calc, fs_method, None)\n",
    "                f_features = [top_features[:n] for n in f_nums]\n",
    "                elapsed.append(time.time() - start_time)\n",
    "\n",
    "                for f_num, curr_f in zip(f_nums, f_features):\n",
    "                    curr_calc.calc_dist_simi_matrix(feature_names=curr_f)\n",
    "                    pen, pens = curr_calc.simi_penalty(n=knn_threshold, dependent=True)\n",
    "\n",
    "                    acc = 1 - (np.sum(pens)/(len(pens)*10))\n",
    "                    curr_accs.append(acc)\n",
    "                all_accs.append(curr_accs)\n",
    "            all_accs = np.average(np.array(all_accs), axis=0)\n",
    "            for f_num, acc in zip(f_nums, all_accs):\n",
    "                curr_method[f_num].append(acc)\n",
    "        main_dict[knn_threshold][fs_method] = curr_method\n",
    "        time_dict[knn_threshold][fs_method] = np.mean(elapsed)\n",
    "        print(np.mean(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a1fe982-ed5b-41a4-985e-c045497189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_table(k=3, sku=None):\n",
    "    name_trans_dict = {\n",
    "        'Forward_SFS_Linear': 'Fw SFS Linear',\n",
    "        'Backward_SFS_Linear': 'Bw SFS Linear',\n",
    "        'Forward_SFS_DecisionTree': 'Fw SFS DecTree',\n",
    "        'Backward_SFS_DecisionTree': 'Bw SFS DecTree',\n",
    "        'Forward_SFS_LogisticRegression': 'Fw SFS LogReg',\n",
    "        'Backward_SFS_LogisticRegression': 'Bw SFS LogReg',\n",
    "        'MutualInfoGain': 'MIGain',\n",
    "        'RFE_Linear': 'RFE Linear',\n",
    "        'RFE_DecisionTree': 'RFE DecTree',\n",
    "        'RFE_LogisticRegression': 'RFE LogReg',\n",
    "    }\n",
    "    \n",
    "    sku_trans_dict = {\n",
    "        'cpu2': 0,\n",
    "        'cpu4': 1,\n",
    "        'cpu8': 2,\n",
    "        'cpu16': 3,\n",
    "    }\n",
    "    \n",
    "    for method, subval in main_dict[k].items():\n",
    "        outstr = '\\\\textcolor{}{'\n",
    "        print_name = method if method not in name_trans_dict else name_trans_dict[method]\n",
    "        outstr += print_name\n",
    "        outstr += '} & '\n",
    "        for fnum, subsubval in subval.items():\n",
    "            if fnum == 29:\n",
    "                continue\n",
    "            if sku is None:\n",
    "                outstr += f'{np.mean(subsubval):.3f} & '\n",
    "            else:\n",
    "                outstr += f'{subsubval[sku_trans_dict[sku]]:.3f} & '\n",
    "        if method == 'Variance':\n",
    "            if sku is None:\n",
    "                all_acc = np.mean(subval[29])\n",
    "            else:\n",
    "                all_acc = subval[29][sku_trans_dict[sku]]\n",
    "            outstr += '\\multirow{17}{*}{'\n",
    "            outstr += '{:.3f}'.format(all_acc)\n",
    "            outstr += '}'\n",
    "        outstr += f' & {time_dict[k][method]:.3f} \\\\\\\\'\n",
    "        print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f0b0078-4cd1-4466-bf1d-33d97c0b6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.307 & 0.702 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.033 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.961 & 0.969 & 0.978 & 0.988 &  & 0.052 \\\\\n",
      "\\textcolor{}{MIGain} & 0.964 & 0.963 & 0.990 & 0.991 &  & 3.246 \\\\\n",
      "\\textcolor{}{Pearson} & 0.961 & 0.969 & 0.978 & 0.990 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.481 & 0.963 & 0.982 & 0.994 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.481 & 0.958 & 0.992 & 0.994 &  & 0.095 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.997 & 0.997 & \\multirow{17}{*}{0.994} & 0.033 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.052 \\\\\n",
      "\\textcolor{}{MIGain} & 0.981 & 0.972 & 0.986 & 0.986 &  & 3.246 \\\\\n",
      "\\textcolor{}{Pearson} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.467 & 0.969 & 0.989 & 0.989 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.467 & 0.969 & 0.992 & 0.989 &  & 0.095 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.786 & 0.994 & 0.994 & \\multirow{17}{*}{0.997} & 0.033 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.947 & 0.944 & 0.953 & 0.989 &  & 0.052 \\\\\n",
      "\\textcolor{}{MIGain} & 0.947 & 0.944 & 0.989 & 0.994 &  & 3.246 \\\\\n",
      "\\textcolor{}{Pearson} & 0.947 & 0.944 & 0.953 & 0.994 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.522 & 0.947 & 0.992 & 0.994 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.522 & 0.947 & 0.986 & 0.994 &  & 0.095 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.625 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.033 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.052 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.964 & 0.992 & 0.992 &  & 3.246 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.467 & 0.961 & 0.953 & 0.997 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.467 & 0.953 & 0.997 & 0.997 &  & 0.095 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.250 & 0.681 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.033 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.052 \\\\\n",
      "\\textcolor{}{MIGain} & 0.975 & 0.969 & 0.992 & 0.992 &  & 3.246 \\\\\n",
      "\\textcolor{}{Pearson} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.469 & 0.972 & 0.994 & 0.997 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.469 & 0.964 & 0.994 & 0.997 &  & 0.095 \\\\\n",
      "2 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.307 & 0.702 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.961 & 0.969 & 0.978 & 0.988 &  & 0.044 \\\\\n",
      "\\textcolor{}{MIGain} & 0.964 & 0.960 & 0.985 & 0.991 &  & 2.611 \\\\\n",
      "\\textcolor{}{Pearson} & 0.961 & 0.969 & 0.978 & 0.990 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.481 & 0.963 & 0.982 & 0.994 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.481 & 0.958 & 0.992 & 0.994 &  & 0.101 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.997 & 0.997 & \\multirow{17}{*}{0.994} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.044 \\\\\n",
      "\\textcolor{}{MIGain} & 0.981 & 0.972 & 0.986 & 0.986 &  & 2.611 \\\\\n",
      "\\textcolor{}{Pearson} & 0.969 & 0.983 & 0.986 & 0.989 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.467 & 0.969 & 0.989 & 0.989 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.467 & 0.969 & 0.992 & 0.989 &  & 0.101 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.786 & 0.994 & 0.994 & \\multirow{17}{*}{0.997} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.947 & 0.944 & 0.953 & 0.989 &  & 0.044 \\\\\n",
      "\\textcolor{}{MIGain} & 0.947 & 0.944 & 0.989 & 0.994 &  & 2.611 \\\\\n",
      "\\textcolor{}{Pearson} & 0.947 & 0.944 & 0.953 & 0.994 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.522 & 0.947 & 0.992 & 0.994 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.522 & 0.947 & 0.986 & 0.994 &  & 0.101 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.247 & 0.625 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.044 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.956 & 0.975 & 0.992 &  & 2.611 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.956 & 0.981 & 0.983 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.467 & 0.961 & 0.953 & 0.997 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.467 & 0.953 & 0.997 & 0.997 &  & 0.101 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.250 & 0.681 & 0.997 & 0.997 & \\multirow{17}{*}{0.997} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.044 \\\\\n",
      "\\textcolor{}{MIGain} & 0.975 & 0.969 & 0.992 & 0.992 &  & 2.611 \\\\\n",
      "\\textcolor{}{Pearson} & 0.975 & 0.994 & 0.992 & 0.992 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.469 & 0.972 & 0.994 & 0.997 &  & 0.052 \\\\\n",
      "\\textcolor{}{ENet} & 0.469 & 0.964 & 0.994 & 0.997 &  & 0.101 \\\\\n",
      "3 -----overall-----\n",
      "\\textcolor{}{Variance} & 0.354 & 0.697 & 0.991 & 0.992 & \\multirow{17}{*}{0.994} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.967 & 0.974 & 0.972 &  & 0.048 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.952 & 0.968 & 0.983 &  & 2.540 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.967 & 0.974 & 0.987 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.482 & 0.954 & 0.960 & 0.989 &  & 0.056 \\\\\n",
      "\\textcolor{}{ENet} & 0.482 & 0.954 & 0.987 & 0.991 &  & 0.110 \\\\\n",
      "-----cpu2-----\n",
      "\\textcolor{}{Variance} & 0.483 & 0.717 & 0.992 & 0.994 & \\multirow{17}{*}{0.994} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.958 & 0.978 & 0.981 & 0.989 &  & 0.048 \\\\\n",
      "\\textcolor{}{MIGain} & 0.958 & 0.958 & 0.981 & 0.981 &  & 2.540 \\\\\n",
      "\\textcolor{}{Pearson} & 0.958 & 0.978 & 0.981 & 0.989 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.467 & 0.958 & 0.972 & 0.989 &  & 0.056 \\\\\n",
      "\\textcolor{}{ENet} & 0.467 & 0.958 & 0.989 & 0.989 &  & 0.110 \\\\\n",
      "-----cpu4-----\n",
      "\\textcolor{}{Variance} & 0.242 & 0.781 & 0.989 & 0.992 & \\multirow{17}{*}{0.992} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.950 & 0.953 & 0.931 &  & 0.048 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.950 & 0.931 & 0.986 &  & 2.540 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.950 & 0.953 & 0.989 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.522 & 0.953 & 0.933 & 0.989 &  & 0.056 \\\\\n",
      "\\textcolor{}{ENet} & 0.522 & 0.953 & 0.981 & 0.992 &  & 0.110 \\\\\n",
      "-----cpu8-----\n",
      "\\textcolor{}{Variance} & 0.242 & 0.619 & 0.992 & 0.992 & \\multirow{17}{*}{0.994} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.950 & 0.953 & 0.975 & 0.983 &  & 0.048 \\\\\n",
      "\\textcolor{}{MIGain} & 0.950 & 0.953 & 0.975 & 0.986 &  & 2.540 \\\\\n",
      "\\textcolor{}{Pearson} & 0.950 & 0.953 & 0.975 & 0.983 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.469 & 0.956 & 0.950 & 0.986 &  & 0.056 \\\\\n",
      "\\textcolor{}{ENet} & 0.469 & 0.950 & 0.992 & 0.992 &  & 0.110 \\\\\n",
      "-----cpu16-----\n",
      "\\textcolor{}{Variance} & 0.450 & 0.672 & 0.992 & 0.992 & \\multirow{17}{*}{0.994} & 0.024 \\\\\n",
      "\\textcolor{}{fANOVA} & 0.953 & 0.986 & 0.986 & 0.986 &  & 0.048 \\\\\n",
      "\\textcolor{}{MIGain} & 0.953 & 0.947 & 0.986 & 0.981 &  & 2.540 \\\\\n",
      "\\textcolor{}{Pearson} & 0.953 & 0.986 & 0.986 & 0.986 &  & 0.035 \\\\\n",
      "\\textcolor{}{Lasso} & 0.469 & 0.950 & 0.986 & 0.992 &  & 0.056 \\\\\n",
      "\\textcolor{}{ENet} & 0.469 & 0.956 & 0.986 & 0.992 &  & 0.110 \\\\\n"
     ]
    }
   ],
   "source": [
    "for k in [1,2,3]:\n",
    "    print(k, \"-----overall-----\")\n",
    "    pretty_print_table(k=k)\n",
    "    for sku in [f'cpu{num}' for num in [2, 4, 8, 16]]:\n",
    "        print(f\"-----{sku}-----\")\n",
    "        pretty_print_table(k=k, sku=sku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a521c-2a88-4f45-9b07-be562b10587f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Present Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b54782c-e2c3-49b8-a4a9-edf1b2913e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(fs_method, knn_threshold, lowery=0):\n",
    "    colors = sns.color_palette(\"colorblind\", len(f_nums))\n",
    "    markers = ['o', 'D', 'P', 'X', '*', '>', 'p', ]\n",
    "    # for each # feature (row in df), plot the accuracy for each sku\n",
    "    X_lab = list(data_by_sku.keys())\n",
    "    X_lab = [e for e in X_lab if 'ter' not in e]\n",
    "\n",
    "    X_lab = X_lab[1:]+X_lab[:1]\n",
    "    print(X_lab)\n",
    "    X = [1, 2, 3, 4]\n",
    "\n",
    "    x = np.arange(len(X_lab))  # the label locations\n",
    "    width = 0.125  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.8,3), constrained_layout=True)\n",
    "\n",
    "    for feature_num, accs in main_dict[knn_threshold][fs_method].items():\n",
    "        offset = width * multiplier\n",
    "        if feature_num > 1:\n",
    "            rects = ax.bar(x + offset, accs, width, label=f'{feature_num} Features', color=colors[multiplier], edgecolor='black')\n",
    "        else:\n",
    "            rects = ax.bar(x + offset, accs, width, label=f'{feature_num} Feature', color=colors[multiplier], edgecolor='black')\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.set_xlabel('SKU')\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xticks(x + width, X_lab)\n",
    "    ax.legend(bbox_to_anchor=(0, 1, 1, 0), loc='lower left', ncol=3, mode='expand')\n",
    "    if lowery == 0:\n",
    "        ax.set_ylim(0, 1.2)\n",
    "        plt.savefig('../figs/n_{}_{}fs_{}.pdf'.format(fs_method, knn_threshold, simi_method))\n",
    "    else:\n",
    "        ax.set_ylim(lowery, 1.1)\n",
    "        plt.savefig('../figs/n_{}_{}fs_{}_{}.pdf'.format(fs_method, knn_threshold, simi_method, lowery))\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload_insights",
   "language": "python",
   "name": "workload_insights"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
