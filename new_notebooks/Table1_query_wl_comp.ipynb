{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f46a6e-e57c-441e-a27e-60ebaf5a9ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for table 1\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "from helpers.expr_data_ch import ExprDataCh\n",
    "from helpers.scale_data import ScaleData\n",
    "from helpers.similarity import Similarity\n",
    "from helpers.feature_selection import FeatureSelection\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import root_mean_squared_error as rmse_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a1bd26-d2b1-454b-8086-3b8826cef17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(47906)\n",
    "random.seed(47906)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e362fff-5003-4ad1-8af8-d7f47518a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_method = 'MutualInfoGain'\n",
    "est_name = 'DecisionTree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37fbc46-edf7-4642-9af9-75955a70df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "SMALL_SMALL_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "plt.rc('legend', fontsize=SMALL_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680253e6-4705-442b-85d8-245751a099e9",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79eeac9-a05c-45d9-9f33-4dc9383be5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = ExprDataCh()\n",
    "data_all.load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867121d9-7099-4aa8-bf74-3454e8dc4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = ['13', '14', '15', '16'] # [wl_tpcc2_tpch2, query_tpcc2_tpch2, wl_tpcc3_tpch1, query_tpcc3_tpch1]\n",
    "candidate_query_group = '16'\n",
    "candidate_wl_group = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3b78c4-f86d-4240-b291-396736ae92c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38', '38', '38', '38']\n"
     ]
    }
   ],
   "source": [
    "chwl_data = data_all.remove_by_wlname([ 'tpcc', 'tpch', 'twitter', 'xml', 'ycsb']) \n",
    "chwl_data = chwl_data.remove_by_group([g for g in all_groups if g != candidate_wl_group])\n",
    "print(chwl_data.run_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ed32e7-f78c-4c6d-a191-1bcf9cfe8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39', '39', '39', '39']\n"
     ]
    }
   ],
   "source": [
    "osq_data = data_all.remove_by_wlname([ 'tpcc', 'tpch', 'twitter', 'xml', 'ycsb']) # remove known data\n",
    "osq_data = osq_data.remove_by_group([g for g in all_groups if g != candidate_query_group])\n",
    "print(osq_data.run_idx)\n",
    "\n",
    "# keep tpch as it is as it provides some other behavior pattern when using different cpu number (const)\n",
    "known_data = data_all.remove_by_wlname(['xml', 'chbenchmark'])\n",
    "sampled_data = known_data.sample_data()\n",
    "data_by_type = sampled_data.split_by_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9adbd2b-852e-4c0a-bb8b-44f995dd8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# osq_data = osq_data.sample_data()\n",
    "# X_label = 'SKU'\n",
    "X_label = 'cpu_num'\n",
    "y_label = 'latency'\n",
    "\n",
    "expr_label = 'EXPR'\n",
    "y_true_label = 'Y_TRUE'\n",
    "y_pred_label = 'Y_PRED'\n",
    "suffix_labels = ['_small', '_large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487b6351-5b67-4819-801c-7f39e17e32d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.357 chbenchmark 22 16 cpu16\n",
      "12.980333333333334 chbenchmark 22 2 cpu2\n",
      "306.635 chbenchmark 22 4 cpu4\n",
      "15.603 chbenchmark 22 8 cpu8\n"
     ]
    }
   ],
   "source": [
    "for tl, tn, tt, tc, ts in zip(osq_data.wl_latency, osq_data.wl_names, osq_data.terminal_num, osq_data.cpu_nums, osq_data.wl_latency_samples):\n",
    "    print(tl, tn, tt, tc[3:], tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7a1f14-2670-4609-beac-95cc7c4389d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_nums_as_X(l):\n",
    "    return np.array([int(e[3:]) for e in l]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd44556f-8ab0-4c44-9bfc-3ef9e9a86774",
   "metadata": {},
   "outputs": [],
   "source": [
    "osq_X = get_cpu_nums_as_X(osq_data.cpu_nums)\n",
    "osq_y = np.array(osq_data.wl_latency)\n",
    "osq_expr = np.array(osq_data.sampled_run_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03068288-adbd-4b22-9bc7-57a58454d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "chwl_X = get_cpu_nums_as_X(chwl_data.cpu_nums)\n",
    "chwl_y = np.array(chwl_data.wl_latency)\n",
    "chwl_expr = np.array(chwl_data.sampled_run_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ac9fa-48f4-4556-a4c4-83124bf73fd2",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47948c17-72e6-4b1a-adc2-8e769f64f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using ONLYknow data\n",
    "scaler = ScaleData()\n",
    "plan_mtxs, plan_col_ranges = scaler.scale(known_data.plan_mtxs)\n",
    "# perf_mtxs, perf_col_ranges = scaler.scale(known_data.perf_mtxs)\n",
    "\n",
    "ksimi_calc = Similarity(known_data, plan_mtxs, plan_col_ranges,[], [])\n",
    "ksimi_calc.calc_bined_mtx(plan_only=True) # all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36592813-8906-4e09-9a80-768be25278fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelection(ksimi_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bddef7e5-bfab-4af0-9df4-61f84193dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 144, 22)\n",
      "['AvgRowSize', 'CachedPlanSize', 'EstimatedAvailableMemoryGrant', 'StatementSubTreeCost', 'EstimatedPagesCached', 'MaxCompileMemory']\n"
     ]
    }
   ],
   "source": [
    "top_7 = fs.select_features(7, 'Lasso', est_name=est_name, direction=None, feature_type='plan')\n",
    "print(top_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b3d32-c7c3-4bc2-b903-f22943ab78a9",
   "metadata": {},
   "source": [
    "# Same model different scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f8b9999-566d-47e6-880f-12809b798076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simis(simi_data, simi_mtx, candid_idx):\n",
    "    print(simi_data.cpu_nums[candid_idx], len(simi_mtx[candid_idx]))\n",
    "    arr = []\n",
    "    true_idx = []\n",
    "    wl_g = []\n",
    "    for idx, val in enumerate(simi_mtx[candid_idx]):\n",
    "        # if simi_data.wl_names[idx] == simi_data.wl_names[candid_idx]:\n",
    "            # arr.append(100000)\n",
    "            # true_idx.append(idx)\n",
    "            # wl_g.append(simi_data.wl_groups[idx])\n",
    "        if simi_data.wl_names[idx] != simi_data.wl_names[candid_idx] and simi_data.cpu_nums[idx] == simi_data.cpu_nums[candid_idx]:\n",
    "            arr.append(val)\n",
    "            true_idx.append(idx)\n",
    "            wl_g.append(simi_data.wl_groups[idx])\n",
    "   \n",
    "    df = pd.DataFrame({'dist': arr, 'true_idx': true_idx, 'wl_groups': wl_g} )\n",
    "    # nearest = np.argsort(arr) \n",
    "    # print(true_idx, arr, nearest)\n",
    "    # idx_order = [true_idx[i] for i in nearest]\n",
    "    # nearest_wls = np.array([simi_data.wl_groups[true_idx[i]] for i in nearest])\n",
    "    # print([true_idx[i] for i in nearest], nearest_wls)\n",
    "    df.sort_values(by=['dist'], ascending=True, inplace=True)\n",
    "    wls = df['wl_groups'].to_list()\n",
    "    tops = []\n",
    "    for wln in wls:\n",
    "        if wln not in tops:\n",
    "            tops.append(wln)\n",
    "\n",
    "    # _, idx = np.unique(wls, return_index=True)\n",
    "    # print(idx)\n",
    "    # print(wls)\n",
    "    # tops = [wls[i] for i in idx]\n",
    "    return tops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3229c-8eb0-48c7-85b6-be09b6fbc62e",
   "metadata": {},
   "source": [
    "### Build models for existing workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b89f9b-1704-46c8-8eff-b32b7e2c49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse_score(y_true, y_pred):\n",
    "    return rmse_score(y_true, y_pred)/(1+np.max(y_true)-np.min(y_true))\n",
    "\n",
    "score_func = make_scorer(nrmse_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94269c8f-e816-4eec-8eda-3ab91a260ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Use a dictionary of models\n",
    "- key: (lower SKU, higher SKU)\n",
    "- value: model\n",
    "'''\n",
    "def trend_predict(model_dicts, X, y_true, expr_idxs, method, sku_pair=None, show_fig=True):\n",
    "    overall_data = pd.DataFrame(zip(X, expr_idxs, y_true), columns=[X_label, expr_label, y_true_label])\n",
    "    # for each pair of SKU\n",
    "    num_cpus = np.sort(np.unique(X))\n",
    "    test_scores = []\n",
    "    models, datas_big, datas_small = [], [], []\n",
    "    dfs = []\n",
    "        \n",
    "    for i in range(len(num_cpus)):\n",
    "        for j in range(i, len(num_cpus)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if sku_pair is not None and (i != sku_pair[0] or j != sku_pair[1]):\n",
    "                continue\n",
    "            cpu_a = num_cpus[i] # smaller\n",
    "            cpu_b = num_cpus[j] # larger\n",
    "            \n",
    "            curr_smaller = overall_data[overall_data[X_label] == cpu_a]\n",
    "            curr_bigger = overall_data[overall_data[X_label] == cpu_b]\n",
    "            \n",
    "            new_preds = []\n",
    "            \n",
    "            for model_dict in model_dicts:            \n",
    "                new_y_true, new_y_pred = [], []\n",
    "\n",
    "                curr_smaller_pred = model_dict[(cpu_a, cpu_b)].predict(curr_smaller[X_label].to_numpy().reshape(-1, 1))\n",
    "                curr_bigger_pred = model_dict[(cpu_a, cpu_b)].predict(curr_bigger[X_label].to_numpy().reshape(-1, 1))\n",
    "                curr_smaller = curr_smaller.assign(Y_PRED=curr_smaller_pred)\n",
    "                curr_bigger = curr_bigger.assign(Y_PRED=curr_bigger_pred)\n",
    "\n",
    "                for _, smaller_row in curr_smaller.iterrows():\n",
    "                    curr_expr_idx = smaller_row[expr_label]\n",
    "                    curr_diff = smaller_row[y_true_label] - smaller_row[y_pred_label]\n",
    "                    bigger_row = curr_bigger[curr_bigger[expr_label] == curr_expr_idx]\n",
    "                    assert(bigger_row.shape[0] == 1)\n",
    "                    bigger_row = bigger_row.iloc[0]\n",
    "                    new_y_true.append(bigger_row[y_true_label])\n",
    "                    new_y_pred.append(bigger_row[y_pred_label] + curr_diff)\n",
    "                new_preds.append(new_y_pred)\n",
    "\n",
    "            curr_bigger = curr_bigger.assign(Y_PRED=np.mean(np.array(new_preds), axis=0))\n",
    "            df = pd.merge(curr_smaller, curr_bigger, on=[expr_label], suffixes=suffix_labels)\n",
    "            dfs.append(df)\n",
    "            \n",
    "            if len(new_y_true) == 1:\n",
    "                score = rmse_score(new_y_true, new_y_pred)/new_y_true[0]\n",
    "            else:\n",
    "                score = rmse_score(new_y_true, new_y_pred)/(1+np.max(new_y_true) - np.min(new_y_true))\n",
    "            test_scores.append(score)\n",
    "                \n",
    "            models.append(model_dict[(cpu_a, cpu_b)])\n",
    "            datas_small.append(curr_smaller)\n",
    "            datas_big.append(curr_bigger)\n",
    "\n",
    "    overall_score = np.mean(test_scores)\n",
    "    return overall_score, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "102bc9bc-e711-46cc-b665-6832a386f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_model(X, y, wl_name, grouping_type, groupping_id, plot=False, show_fig=False):  \n",
    "    train_rmses, test_rmses = [], []\n",
    "    k = 5\n",
    "    num_cpus = np.sort(np.unique(X))\n",
    "    train_time = 0\n",
    "    model_dict = {}\n",
    "    models = []\n",
    "    fold_test_rmses = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        start = time.time()\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(X_train, y_train)\n",
    "        test_pred = reg.predict(X_test)\n",
    "        train_pred = reg.predict(X_train)\n",
    "        end = time.time()\n",
    "        train_time += end - start\n",
    "        \n",
    "        num_pairs = 0\n",
    "        for i in range(len(num_cpus)):\n",
    "            for j in range(i, len(num_cpus)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                cpu_a = num_cpus[i] # smaller\n",
    "                cpu_b = num_cpus[j] # larger\n",
    "                curr_mask = [x_lab == cpu_a or x_lab == cpu_b for x_lab in X_test.flatten()]\n",
    "\n",
    "                curr_y_true = y_test[curr_mask]\n",
    "                # rmse = np.sqrt(((curr_y_true-test_pred[curr_mask])**2).mean())\n",
    "                rmse = rmse_score(curr_y_true, test_pred[curr_mask])\n",
    "                if len(curr_y_true) == 1:\n",
    "                    n_rmse = rmse/curr_y_true[0]\n",
    "                else:\n",
    "                    n_rmse = rmse / (1+np.max(curr_y_true)-np.min(curr_y_true))\n",
    "                # n_rmse = rmse / (1+np.max(curr_y_true)-np.min(curr_y_true))\n",
    "                test_rmses.append(n_rmse)\n",
    "                \n",
    "                curr_mask = [x_lab == cpu_a or x_lab == cpu_b for x_lab in X_train.flatten()]\n",
    "                \n",
    "                curr_y_true = y_train[curr_mask]\n",
    "                rmse = rmse_score(curr_y_true, train_pred[curr_mask])\n",
    "                # rmse = np.sqrt(((curr_y_true-train_pred[curr_mask])**2).mean())\n",
    "                if len(curr_y_true) == 1:\n",
    "                    n_rmse = rmse/curr_y_true[0]\n",
    "                else:\n",
    "                    n_rmse = rmse / (1+np.max(curr_y_true)-np.min(curr_y_true))\n",
    "                train_rmses.append(n_rmse)\n",
    "                num_pairs == 1\n",
    "                \n",
    "        fold_test_rmses.append(np.mean(test_rmses[-num_pairs:]))\n",
    "        models.append(reg)\n",
    "    \n",
    "    train_time /= k\n",
    "    \n",
    "    best_model = models[np.argmin(fold_test_rmses)]\n",
    "    for i in range(len(num_cpus)):\n",
    "        for j in range(i, len(num_cpus)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            cpu_a = num_cpus[i] # smaller\n",
    "            cpu_b = num_cpus[j] # larger\n",
    "            model_dict[(cpu_a, cpu_b)] = best_model\n",
    "\n",
    "    overall_test_rmse = np.mean(test_rmses)\n",
    "    overall_train_rmse = np.mean(train_rmses)\n",
    "    return overall_test_rmse, overall_train_rmse, model_dict, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52cb86cd-62e1-4a5f-94ea-022b209ac8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm_model_indi(X, y, wl_name, grouping_type, groupping_id, show_fig=True):  \n",
    "    metrics = [X_label, y_label]\n",
    "    zipped = zip(X, y)\n",
    "\n",
    "    # append fixed effect and random effect to data\n",
    "    overall_data = pd.DataFrame(zipped, columns=metrics)\n",
    "    \n",
    "    train_scores, test_scores = [], []\n",
    "\n",
    "    models, datas = [], []\n",
    "    model_dict = {}\n",
    "    \n",
    "    # epsilon range: according to this paper: http://adrem.uantwerpen.be/bibrem/pubs/IJCNN2007.pdf\n",
    "    # C range: https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "    \n",
    "    # Cross validation grid search (best parameters) \n",
    "    # c_range = np.logspace(1, 100, 10) # 1 and 100\n",
    "    c_range = np.logspace(-5, 5, base=2.0, num=5) # 1 and 100\n",
    "    epsilon_range = np.linspace(10 ** -3, 1, 5) # 1-e3 and 1\n",
    "    # gamma_range = np.logspace(-4, 0, 20) # 2^{-15} to 2^3\n",
    "    degree_range = np.array(list(range(1, 5)))\n",
    "    tuned_parameters = [{'kernel': ['rbf'],'C': c_range, 'epsilon': epsilon_range}, # 'gamma':gamma_range,\n",
    "                        {'kernel': ['linear'], 'C': c_range, 'epsilon': epsilon_range}, # 'gamma':gamma_range,\n",
    "                        {'kernel': ['poly'], 'C': c_range, 'degree': degree_range, 'epsilon': epsilon_range} # 'gamma':gamma_range,\n",
    "                       ]\n",
    "\n",
    "    num_cpus = np.sort(np.unique(X))\n",
    "    prev_cpu = num_cpus[0]\n",
    "\n",
    "    train_time = 0\n",
    "    for i in range(len(num_cpus)):\n",
    "        for j in range(i, len(num_cpus)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            cpu_a = num_cpus[i] # smaller\n",
    "            cpu_b = num_cpus[j] # larger\n",
    "            curr_data = overall_data[ (overall_data[X_label] == cpu_a) | (overall_data[X_label] == cpu_b) ]\n",
    "            \n",
    "            svr = SVR()\n",
    "            datas.append(curr_data)\n",
    "            clf = GridSearchCV(svr,param_grid=tuned_parameters,verbose=0, n_jobs=4,\n",
    "                               cv=5, \n",
    "                               scoring=score_func, \n",
    "                               return_train_score=True)\n",
    "            clf.fit(curr_data[[X_label]], curr_data[y_label])           \n",
    "            best_params = clf.best_params_\n",
    "            results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "            results_best = results[results['params'] == best_params].reset_index()\n",
    "            train_time += results_best['mean_fit_time'][0]\n",
    "\n",
    "            test_scores.append(results_best.iloc[0]['mean_test_score'])\n",
    "            train_scores.append(results_best.iloc[0]['mean_train_score'])\n",
    "            models.append(clf)\n",
    "            model_dict[(cpu_a, cpu_b)] = clf\n",
    "    \n",
    "    # plot the last one as example\n",
    "    overall_test = np.mean(test_scores)\n",
    "    overall_train = np.mean(train_scores)\n",
    "    return overall_test, overall_train, model_dict, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c41b2b88-edae-4454-b2bd-07c9fe96a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_and_pred(group_to_model_dict, tops, k, name, X, y, expr):\n",
    "    min_groups = tops[:k]\n",
    "    model_dict = [group_to_model_dict[min_group] for min_group in min_groups]\n",
    "    overall_score, _ = trend_predict(model_dict, X, y, expr, name, None, False)\n",
    "\n",
    "    print('{} Overall ycsb nrmse: {}'.format(name, overall_score))\n",
    "    for p in [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3)]:\n",
    "        pair_score, _ = trend_predict(model_dict, X, y, expr, f'name-{p[0]}-{p[1]}',  p, False)\n",
    "        print('{} pairwise ycsb nrmse: {}'.format(p, pair_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f533178-da70-4efa-a25d-49e83298e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0b54596-18e2-4f2f-89d3-66ea1de9ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests, all_trains = [], []\n",
    "svm_model_dict = {}\n",
    "\n",
    "for ty, curr_data in data_by_type.items():\n",
    "    # # if ty not in tops:\n",
    "    # #     continue\n",
    "    # min_idx, = np.where(np.array(known_data.wl_groups) == ty)\n",
    "    # print(np.unique(np.array(known_data.wl_names)[min_idx]))\n",
    "    X = get_cpu_nums_as_X(curr_data.cpu_nums)\n",
    "    y = np.array(curr_data.wl_latency)\n",
    "    _, _, model_dict, _ = build_svm_model_indi(X, y, curr_data.wl_names[0], 'group', \n",
    "                                               curr_data.wl_groups[0], show_fig=False)\n",
    "    svm_model_dict[ty] = model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87093d-7e15-4b31-8baa-6ffceab6799b",
   "metadata": {},
   "source": [
    "# Use Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6125f-9515-43c6-bff9-843043c28a39",
   "metadata": {},
   "source": [
    "### Similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe571f1a-2bc8-48a1-a05c-126212213219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity computation using known data and experiment data\n",
    "simi_query_data = data_all.remove_by_wlname(['xml', 'chbenchmark'])\n",
    "simi_query_data = simi_query_data.remove_by_group([g for g in all_groups if g != candidate_query_group])\n",
    "scaler = ScaleData()\n",
    "plan_mtxs, plan_col_ranges = scaler.scale(simi_query_data.plan_mtxs)\n",
    "\n",
    "simi_calc = Similarity(simi_query_data, plan_mtxs, plan_col_ranges, [], [])\n",
    "simi_calc.calc_bined_mtx(plan_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d6faf78b-a8f4-44b8-a667-81615a0cf15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simi calculation time 0.09764814376831055\n"
     ]
    }
   ],
   "source": [
    "simi_calc.calc_dist_simi_matrix(cumulative=True, feature_names=top_7, norm_type='l21', timeit=True)\n",
    "simi_mtx = simi_calc.simi_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b21ae232-f93c-481a-9177-84273fc7f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu8 144\n"
     ]
    }
   ],
   "source": [
    "candid_idx = len(simi_query_data.wl_names) - 1\n",
    "tops = get_simis(simi_query_data, simi_mtx, candid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9af45189-fb54-44f9-ba5e-31b421d07eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '7', '8', '3', '4']\n",
      "['tpcc'] cpu8 [32] ['1']\n",
      "['tpcc'] cpu8 [8] ['7']\n",
      "['tpcc'] cpu8 [4] ['8']\n",
      "['twitter'] cpu8 [32] ['3']\n",
      "['twitter'] cpu8 [8] ['4']\n"
     ]
    }
   ],
   "source": [
    "tops = tops[:5]\n",
    "print(tops)\n",
    "\n",
    "for wl in tops:\n",
    "    min_idx, = np.where(np.array(known_data.wl_groups) == wl)\n",
    "    print(np.unique(np.array(known_data.wl_names)[min_idx]), known_data.cpu_nums[candid_idx], \n",
    "          np.unique(np.array(known_data.terminal_num)[min_idx]), \n",
    "          np.unique(np.array(known_data.wl_groups)[min_idx])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ef248-b39a-4543-ac7b-1a7fec1f69ad",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc59b550-d5bb-409a-8955-c9aee150913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "svm Overall ycsb nrmse: 4.001788753571488\n",
      "(0, 1) pairwise ycsb nrmse: 0.9511344468510646\n",
      "(0, 2) pairwise ycsb nrmse: 0.2451167301960221\n",
      "(1, 2) pairwise ycsb nrmse: 18.751294266818242\n",
      "(1, 3) pairwise ycsb nrmse: 2.5996479460467303\n",
      "(2, 3) pairwise ycsb nrmse: 0.7531381444658894\n",
      "['1', '7']\n",
      "svm Overall ycsb nrmse: 4.032247453116313\n",
      "(0, 1) pairwise ycsb nrmse: 0.9600723263101791\n",
      "(0, 2) pairwise ycsb nrmse: 0.07372513617068317\n",
      "(1, 2) pairwise ycsb nrmse: 19.004756920130003\n",
      "(1, 3) pairwise ycsb nrmse: 2.64695415105039\n",
      "(2, 3) pairwise ycsb nrmse: 0.7804096883729957\n",
      "['1', '7', '8']\n",
      "svm Overall ycsb nrmse: 4.036228015154044\n",
      "(0, 1) pairwise ycsb nrmse: 0.9718184667685695\n",
      "(0, 2) pairwise ycsb nrmse: 0.1602227854597051\n",
      "(1, 2) pairwise ycsb nrmse: 18.878903666341905\n",
      "(1, 3) pairwise ycsb nrmse: 2.631678948009263\n",
      "(2, 3) pairwise ycsb nrmse: 0.7785802848445305\n"
     ]
    }
   ],
   "source": [
    "for k in [1 ,2, 3]:\n",
    "    chose_and_pred(svm_model_dict, tops, k, 'svm', osq_X, osq_y, osq_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e692cb5-d3e3-4e17-a85c-a8d65562201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '7']\n",
      "  cpu_num_small EXPR  Y_TRUE_small  Y_PRED_small cpu_num_large  Y_TRUE_large  \\\n",
      "0           [4]   39       306.635    390.758333          [16]        87.357   \n",
      "\n",
      "   Y_PRED_large       Diff  Perc_Diff  \n",
      "0     316.52071  229.16371   0.724009  \n"
     ]
    }
   ],
   "source": [
    "min_groups = tops[:2]\n",
    "model_dict = [svm_model_dict[min_group] for min_group in min_groups]\n",
    "print(min_groups)\n",
    "\n",
    "pair_score, dfs = trend_predict(model_dict, osq_X, osq_y, osq_expr, f'svm13',  (1, 3), False)\n",
    "curr_df = dfs[0]\n",
    "curr_df['Diff'] = abs(curr_df['Y_TRUE_large']-curr_df['Y_PRED_large'])\n",
    "curr_df['Perc_Diff'] = curr_df['Diff']/curr_df['Y_PRED_large']\n",
    "temp = curr_df[['Y_TRUE_small', 'Y_TRUE_large', 'Y_PRED_large', 'Diff', 'Perc_Diff']]\n",
    "print(curr_df[curr_df['Diff'] == curr_df['Diff'].min()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a31cc-8533-439d-b667-07fdd7702e86",
   "metadata": {},
   "source": [
    "# Use workload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3193ad8-9c0d-493f-8300-b50320cc38b9",
   "metadata": {},
   "source": [
    "### Similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df59b5f4-95c2-4c84-96f0-6c7931a9a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity computation using known data and experiment data\n",
    "simi_wl_data = data_all.remove_by_wlname(['xml', 'chbenchmark'])\n",
    "simi_wl_data = simi_wl_data.remove_by_group([g for g in all_groups if g != candidate_wl_group])\n",
    "scaler = ScaleData()\n",
    "plan_mtxs, plan_col_ranges = scaler.scale(simi_wl_data.plan_mtxs)\n",
    "\n",
    "simi_calc = Similarity(simi_wl_data, plan_mtxs, plan_col_ranges, [], [])\n",
    "simi_calc.calc_bined_mtx(plan_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e53d4101-7ec2-4522-96e8-6bd2d30e94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simi calculation time 0.09092044830322266\n"
     ]
    }
   ],
   "source": [
    "simi_calc.calc_dist_simi_matrix(cumulative=True, feature_names=top_7, norm_type='l21', timeit=True)\n",
    "simi_mtx = simi_calc.simi_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b3746e38-51a5-4ec9-88dd-203d6fe71386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu8 144\n"
     ]
    }
   ],
   "source": [
    "candid_idx = len(simi_wl_data.wl_names) - 1\n",
    "tops = get_simis(simi_wl_data, simi_mtx, candid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "85db62d8-afba-4306-93dd-b0bd1617a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '7', '8', '3', '4']\n",
      "['tpcc'] cpu8 [32] ['1']\n",
      "['tpcc'] cpu8 [8] ['7']\n",
      "['tpcc'] cpu8 [4] ['8']\n",
      "['twitter'] cpu8 [32] ['3']\n",
      "['twitter'] cpu8 [8] ['4']\n"
     ]
    }
   ],
   "source": [
    "tops = tops[:5]\n",
    "print(tops)\n",
    "\n",
    "for wl in tops:\n",
    "    min_idx, = np.where(np.array(simi_wl_data.wl_groups) == wl)\n",
    "    print(np.unique(np.array(simi_wl_data.wl_names)[min_idx]), simi_wl_data.cpu_nums[candid_idx], \n",
    "          np.unique(np.array(simi_wl_data.terminal_num)[min_idx]), \n",
    "          np.unique(np.array(simi_wl_data.wl_groups)[min_idx])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "728b2cbd-9091-44b5-8155-69f24fb12a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "svm Overall ycsb nrmse: 16.226161618987845\n",
      "(0, 1) pairwise ycsb nrmse: 0.31062742090184176\n",
      "(0, 2) pairwise ycsb nrmse: 54.33577459654684\n",
      "(1, 2) pairwise ycsb nrmse: 41.14297830072808\n",
      "(1, 3) pairwise ycsb nrmse: 0.12555131981344478\n",
      "(2, 3) pairwise ycsb nrmse: 0.9667855207642678\n",
      "['1', '7']\n",
      "svm Overall ycsb nrmse: 16.235639792093576\n",
      "(0, 1) pairwise ycsb nrmse: 0.3078806894508524\n",
      "(0, 2) pairwise ycsb nrmse: 54.2230000407514\n",
      "(1, 2) pairwise ycsb nrmse: 41.30975508053761\n",
      "(1, 3) pairwise ycsb nrmse: 0.13017673705010518\n",
      "(2, 3) pairwise ycsb nrmse: 0.9694520265482028\n",
      "['1', '7', '8']\n",
      "svm Overall ycsb nrmse: 16.19418375895415\n",
      "(0, 1) pairwise ycsb nrmse: 0.3042709413475817\n",
      "(0, 2) pairwise ycsb nrmse: 54.06906382765314\n",
      "(1, 2) pairwise ycsb nrmse: 41.226944456877355\n",
      "(1, 3) pairwise ycsb nrmse: 0.12868318694532616\n",
      "(2, 3) pairwise ycsb nrmse: 0.9692731545669752\n"
     ]
    }
   ],
   "source": [
    "for k in [1 ,2, 3]:\n",
    "    chose_and_pred(svm_model_dict, tops, k, 'svm', chwl_X, chwl_y, chwl_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "28bfe593-bf5c-4220-b682-78f0c30113ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '7']\n",
      "  cpu_num_small EXPR  Y_TRUE_small  Y_PRED_small cpu_num_large  Y_TRUE_large  \\\n",
      "0           [4]   38       997.792    390.758333          [16]       893.439   \n",
      "\n",
      "   Y_PRED_large       Diff  Perc_Diff  \n",
      "0    1007.67771  114.23871   0.113368  \n"
     ]
    }
   ],
   "source": [
    "min_groups = tops[:2]\n",
    "model_dict = [svm_model_dict[min_group] for min_group in min_groups]\n",
    "print(min_groups)\n",
    "\n",
    "pair_score, dfs = trend_predict(model_dict, chwl_X, chwl_y, chwl_expr, f'svm13',  (1, 3), False)\n",
    "curr_df = dfs[0]\n",
    "curr_df['Diff'] = abs(curr_df['Y_TRUE_large']-curr_df['Y_PRED_large'])\n",
    "curr_df['Perc_Diff'] = curr_df['Diff']/curr_df['Y_PRED_large']\n",
    "temp = curr_df[['Y_TRUE_small', 'Y_TRUE_large', 'Y_PRED_large', 'Diff', 'Perc_Diff']]\n",
    "print(curr_df[curr_df['Diff'] == curr_df['Diff'].min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75633898-8642-4adf-a5cb-92f4c9fe63be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d52bae-8d96-4140-b45e-62f17d1f1326",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Other Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e2d9cd5a-f35a-4141-8fac-6185c84d75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 144, 22)\n",
      "['AvgRowSize', 'CachedPlanSize', 'MaxCompileMemory']\n"
     ]
    }
   ],
   "source": [
    "top_3 = fs.select_features(3, 'Chi2', est_name=None, direction=None, feature_type='plan')\n",
    "print(top_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0c255fe3-8115-478f-862d-e7bb615263aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 144)\n"
     ]
    }
   ],
   "source": [
    "simi_calc.calc_plan_lcss_simi_matrix(plan_feature_names=None)\n",
    "# simi_calc.calc_plan_simi_matrix(plan_feature_names=top_3,  norm_type='corr')\n",
    "\n",
    "simi_mtx = simi_calc.simi_mtx\n",
    "print(simi_mtx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51d2a4e7-4e10-42d2-86d7-fed0d74ea9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu8 144\n"
     ]
    }
   ],
   "source": [
    "tops = get_simis(simi_wl_data, simi_mtx, candid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d6af20c2-4d11-443c-b8e0-31594c6fe238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '9', '4', '3', '6']\n",
      "['tpcc'] cpu8 [32] ['1']\n",
      "['twitter'] cpu8 [4] ['9']\n",
      "['twitter'] cpu8 [8] ['4']\n",
      "['twitter'] cpu8 [32] ['3']\n",
      "['tpch'] cpu8 [4] ['6']\n"
     ]
    }
   ],
   "source": [
    "tops = tops[:5]\n",
    "print(tops)\n",
    "for wl in tops:\n",
    "    min_idx, = np.where(np.array(simi_wl_data.wl_groups) == wl)\n",
    "    print(np.unique(np.array(simi_wl_data.wl_names)[min_idx]), simi_wl_data.cpu_nums[candid_idx], \n",
    "          np.unique(np.array(simi_wl_data.terminal_num)[min_idx]), \n",
    "          np.unique(np.array(simi_wl_data.wl_groups)[min_idx])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5239bfd-88ed-4786-8d0c-54393d9976ea",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ad65ee0-ffcc-43b0-9c71-af93bee20f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9d62e767-d8a4-4d42-946a-c449b5e2e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests, all_trains = [], []\n",
    "reg_model_dict = {}\n",
    "reg_results = {}\n",
    "\n",
    "for ty, curr_data in data_by_type.items():\n",
    "    if ty not in tops:\n",
    "        continue\n",
    "    X = get_cpu_nums_as_X(curr_data.cpu_nums)\n",
    "    y = np.array(curr_data.wl_latency)\n",
    "    _, _, model_dict, _ = build_regression_model(X, y, curr_data.wl_names[0], 'group', \n",
    "                                                 curr_data.wl_groups[0], show_fig=False)\n",
    "    reg_model_dict[ty] = model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c4fa2b6c-6710-48bc-96a8-6bd93f5de8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "reg Overall ycsb nrmse: 16.303640988634715\n",
      "(0, 1) pairwise ycsb nrmse: 0.31232140574199324\n",
      "(0, 2) pairwise ycsb nrmse: 54.53120230398282\n",
      "(1, 2) pairwise ycsb nrmse: 41.38938979278159\n",
      "(1, 3) pairwise ycsb nrmse: 0.14160541510801475\n",
      "(2, 3) pairwise ycsb nrmse: 0.9569212891843095\n",
      "['1', '9']\n",
      "reg Overall ycsb nrmse: 16.575034921227353\n",
      "(0, 1) pairwise ycsb nrmse: 0.3196749119962866\n",
      "(0, 2) pairwise ycsb nrmse: 55.459461450335155\n",
      "(1, 2) pairwise ycsb nrmse: 42.00822922368315\n",
      "(1, 3) pairwise ycsb nrmse: 0.19087975647312785\n",
      "(2, 3) pairwise ycsb nrmse: 0.9240717282742341\n",
      "['1', '9', '4']\n",
      "reg Overall ycsb nrmse: 16.03475950221707\n",
      "(0, 1) pairwise ycsb nrmse: 0.3050359750282424\n",
      "(0, 2) pairwise ycsb nrmse: 53.6115365742901\n",
      "(1, 2) pairwise ycsb nrmse: 40.776279306319786\n",
      "(1, 3) pairwise ycsb nrmse: 0.09278723401629249\n",
      "(2, 3) pairwise ycsb nrmse: 0.9894667432454582\n"
     ]
    }
   ],
   "source": [
    "for k in [1 ,2, 3]:\n",
    "    chose_and_pred(reg_model_dict, tops, k, 'reg', chwl_X, chwl_y, chwl_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "896e5c01-e8cc-448b-b073-0b5be4ff2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '9']\n",
      "  cpu_num_small EXPR  Y_TRUE_small  Y_PRED_small cpu_num_large  Y_TRUE_large  \\\n",
      "0           [4]   38       997.792   2952.623365          [16]       893.439   \n",
      "\n",
      "   Y_PRED_large       Diff  Perc_Diff  \n",
      "0    1041.96661  148.52761   0.142545  \n"
     ]
    }
   ],
   "source": [
    "min_groups = tops[:2]\n",
    "model_dict = [reg_model_dict[min_group] for min_group in min_groups]\n",
    "print(min_groups)\n",
    "\n",
    "pair_score, dfs = trend_predict(model_dict, chwl_X, chwl_y, chwl_expr, f'svm13', (1, 3), False)\n",
    "curr_df = dfs[0]\n",
    "curr_df['Diff'] = abs(curr_df['Y_TRUE_large']-curr_df['Y_PRED_large'])\n",
    "curr_df['Perc_Diff'] = curr_df['Diff']/curr_df['Y_PRED_large']\n",
    "temp = curr_df[['Y_TRUE_small', 'Y_TRUE_large', 'Y_PRED_large', 'Diff', 'Perc_Diff']]\n",
    "print(curr_df[curr_df['Diff'] == curr_df['Diff'].min()])\n",
    "# temp.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload_insights",
   "language": "python",
   "name": "workload_insights"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
